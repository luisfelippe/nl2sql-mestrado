{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "X5GQpZ2YND7y"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -q jsonlines\n",
        "!pip install -q datasets transformers torch evaluate\n",
        "!pip install -q rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!python -m spacy download pt_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "wCj9gEpPmFfu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq0pDYpFe5JD"
      },
      "source": [
        "**Monta o Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GACRrJmUmRSl",
        "outputId": "137a3162-5fdd-4dc0-edbd-2c4bcce37b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTfTjCnjuZq5"
      },
      "source": [
        "**Define as constantes globais**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "38i3TaIXt9AY"
      },
      "outputs": [],
      "source": [
        "# Nome do dataset alvo, dentre os datasets listados em SQL_DATA_INFO\n",
        "DATASET_TARGET = \"spider-en\"\n",
        "\n",
        "# idioma alvo do treinamento para filtro do dataset\n",
        "LANGUAGE_TARGET = \"EN\"\n",
        "\n",
        "# MODEL = 'google/flan-t5-large' # quebrou com outofmemory no pytorch na linha de treinamento\n",
        "\n",
        "# TODO reduzir o batch size para testar\n",
        "# MODEL = 'google/flan-t5-base' # quebrou com outofmemory no pytorch na linha de treinamento\n",
        "MODEL = 'google/flan-t5-small'\n",
        "\n",
        "# controla se deve ou não salvar as épocas durante o treinamento\n",
        "SHOULD_SAVE_EPOCH = False\n",
        "\n",
        "# numero de épocas a ser treinado\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "USE_FP16 = False\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/Mestrado/Projeto\"\n",
        "\n",
        "DATA_PATH = f\"{BASE}/data\"\n",
        "DATA_OUTPUT_PATH = f\"{DATA_PATH}/{DATASET_TARGET}-ajusted\"\n",
        "\n",
        "MODELS_PATH = f\"{BASE}/models\"\n",
        "TRAINNING_PATH = f\"{BASE}/training\"\n",
        "\n",
        "OUTPUT_MODEL = f\"{MODELS_PATH}/{DATASET_TARGET}-{MODEL.replace('/', '-')}\"\n",
        "\n",
        "\n",
        "PREFIX_ANNOTATED = \"annotated-\"\n",
        "PREFIX_PROCESSED = \"processed-\"\n",
        "PREFIX_ONE_SHOT = \"processed-one-shot-\"\n",
        "\n",
        "\n",
        "SQL_DATA_INFO = {\n",
        "    \"spider-en-pt\" : {\n",
        "        \"name\":\"spider-en-pt\",\n",
        "        \"languages\": ['EN', 'PT'],\n",
        "        \"train_tables\":\"tables.json\",\n",
        "        \"dev_tables\":\"tables.json\",\n",
        "        \"eval_tables\":\"tables.json\",\n",
        "        \"train_file\": \"train_spider.json\",\n",
        "        \"evaluate_file\": \"train_others.json\",\n",
        "        \"dev_file\": \"dev.json\",\n",
        "        \"db_id_name\": \"db_id\",\n",
        "        \"output_name\": \"query\",\n",
        "        \"is_multiple_turn\": False,\n",
        "    },\n",
        "    \"spider-en\" : {\n",
        "        \"name\":\"spider-en\",\n",
        "        \"languages\": ['EN'],\n",
        "        \"train_tables\":\"tables.json\",\n",
        "        \"dev_tables\":\"tables.json\",\n",
        "        \"eval_tables\":\"tables.json\",\n",
        "        \"train_file\": \"train_spider.json\",\n",
        "        \"evaluate_file\": \"train_others.json\",\n",
        "        \"dev_file\": \"dev.json\",\n",
        "        \"db_id_name\": \"db_id\",\n",
        "        \"output_name\": \"query\",\n",
        "        \"is_multiple_turn\": False,\n",
        "    },\n",
        "    \"spider-pt\" : {\n",
        "        \"name\":\"spider-pt\",\n",
        "        \"languages\": ['PT'],\n",
        "        \"train_tables\":\"tables.json\",\n",
        "        \"dev_tables\":\"tables.json\",\n",
        "        \"eval_tables\":\"tables.json\",\n",
        "        \"train_file\": \"train_spider.json\",\n",
        "        \"evaluate_file\": \"train_others.json\",\n",
        "        \"dev_file\": \"dev.json\",\n",
        "        \"db_id_name\": \"db_id\",\n",
        "        \"output_name\": \"query\",\n",
        "        \"is_multiple_turn\": False,\n",
        "    },\n",
        "    # \"bird\" : {\n",
        "    #     \"name\": \"bird\",\n",
        "    #     \"train_file\": \"train/train.json\",\n",
        "    #     \"evaluate_file\": \"\",\n",
        "    #     \"dev_file\": \"dev/dev.json\",\n",
        "    #     \"train_tables\": \"train/train_tables.json\",\n",
        "    #     \"eval_tables\": \"train/train_tables.json\",\n",
        "    #     \"dev_tables\": \"dev/dev_tables.json\",\n",
        "    #     \"db_id_name\": \"db_id\",\n",
        "    #     \"output_name\": \"SQL\",\n",
        "    #     \"is_multiple_turn\": False,\n",
        "    # }\n",
        "}\n",
        "\n",
        "INSTRUCTION_PROMPT = \"\"\"\\\n",
        "I want you to act as a SQL terminal in front of an example database, \\\n",
        "you need only to return the sql command to me.Below is an instruction that describes a task, \\\n",
        "Write a response that appropriately completes the request.\\n\"\n",
        "##Instruction:\\n{}\\n\"\"\"\n",
        "\n",
        "INSTRUCTION_ONE_SHOT_PROMPT = \"\"\"\\\n",
        "I want you to act as a SQL terminal in front of an example database. \\\n",
        "You need only to return the sql command to me. \\\n",
        "First, I will show you few examples of an instruction followed by the correct SQL response. \\\n",
        "Then, I will give you a new instruction, and you should write the SQL response that appropriately completes the request.\\\n",
        "\\n### Example1 Instruction:\n",
        "The database contains tables such as employee, salary, and position. \\\n",
        "Table employee has columns such as employee_id, name, age, and position_id. employee_id is the primary key. \\\n",
        "Table salary has columns such as employee_id, amount, and date. employee_id is the primary key. \\\n",
        "Table position has columns such as position_id, title, and department. position_id is the primary key. \\\n",
        "The employee_id of salary is the foreign key of employee_id of employee. \\\n",
        "The position_id of employee is the foreign key of position_id of position.\\\n",
        "\\n### Example1 Input:\\nList the names and ages of employees in the 'Engineering' department.\\n\\\n",
        "\\n### Example1 Response:\\nSELECT employee.name, employee.age FROM employee JOIN position ON employee.position_id = position.position_id WHERE position.department = 'Engineering';\\\n",
        "\\n###New Instruction:\\n{}\\n\"\"\"\n",
        "\n",
        "INPUT_PROMPT = \"###Input:\\n{}\\n\\n###Response:\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kf1YFK8uUhX"
      },
      "source": [
        "## Pipeline T5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hcH7T0Sx0FS"
      },
      "source": [
        "### Processa o Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-CjM7IOtv5Z4"
      },
      "outputs": [],
      "source": [
        "# Adiciona a informação do idioma para cada amostra\n",
        "from typing import List\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "\n",
        "class DatasetMarker:\n",
        "  def __init__(self, dataset):\n",
        "     self.dataset = dataset\n",
        "\n",
        "  def process(self):\n",
        "    \"\"\" Processa o dataset \"\"\"\n",
        "\n",
        "    if self.dataset is not None:\n",
        "      for file in [self.dataset['train_file'], self.dataset['evaluate_file'], self.dataset['dev_file']]:\n",
        "        self.__process_file(file)\n",
        "\n",
        "  def __complexity_discover_of_query(self, sql_query):\n",
        "    \"\"\"Classifica o nível de dificuldade do SQL com base nos critérios do Spider.\"\"\"\n",
        "\n",
        "    # Contar o número de colunas no SELECT\n",
        "    select_match = re.search(\n",
        "        r\"\\bSELECT\\b\\s+(.*?)(\\bFROM\\b)\", sql_query, re.IGNORECASE | re.DOTALL\n",
        "    )\n",
        "    if select_match:\n",
        "        select_columns = select_match.group(1).split(\",\")\n",
        "        num_select = len([col.strip() for col in select_columns if col.strip()])\n",
        "    else:\n",
        "        num_select = 0\n",
        "\n",
        "    # Contar o número de condições no WHERE\n",
        "    where_conditions = re.findall(\n",
        "        r\"\\bWHERE\\b(.*?)(\\bGROUP BY\\b|\\bORDER BY\\b|$)\",\n",
        "        sql_query,\n",
        "        re.IGNORECASE | re.DOTALL,\n",
        "    )\n",
        "    num_where = 0\n",
        "    if where_conditions:\n",
        "        where_clause = where_conditions[0][0]\n",
        "        num_where = (\n",
        "            len(re.findall(r\"AND|OR\", where_clause, re.IGNORECASE))\n",
        "            if where_clause.strip()\n",
        "            else 0\n",
        "        )\n",
        "\n",
        "    # Contar o número de colunas no GROUP BY\n",
        "    group_by_match = re.search(\n",
        "        r\"\\bGROUP BY\\b\\s+(.*?)(\\bORDER BY\\b|$)\",\n",
        "        sql_query,\n",
        "        re.IGNORECASE | re.DOTALL,\n",
        "    )\n",
        "    if group_by_match:\n",
        "        group_by_columns = group_by_match.group(1).split(\",\")\n",
        "        num_group_by = len([col.strip() for col in group_by_columns if col.strip()])\n",
        "    else:\n",
        "        num_group_by = 0\n",
        "\n",
        "    # Contar o número de colunas no ORDER BY\n",
        "    order_by_match = re.search(\n",
        "        r\"\\bORDER BY\\b\\s+(.*?)(LIMIT|$)\", sql_query, re.IGNORECASE | re.DOTALL\n",
        "    )\n",
        "    if order_by_match:\n",
        "        order_by_columns = order_by_match.group(1).split(\",\")\n",
        "        num_order_by = len([col.strip() for col in order_by_columns if col.strip()])\n",
        "    else:\n",
        "        num_order_by = 0\n",
        "\n",
        "    # Contar subconsultas com base nos parênteses\n",
        "    num_nested = len(re.findall(r\"\\(SELECT\\b\", sql_query, re.IGNORECASE))\n",
        "\n",
        "    # Contar o número de junções (JOIN)\n",
        "    num_joins = len(re.findall(r\"\\bJOIN\\b\", sql_query, re.IGNORECASE))\n",
        "\n",
        "    # Verificar a presença de EXCEPT, INTERSECT e UNION\n",
        "    has_except = bool(re.search(r\"\\bEXCEPT\\b\", sql_query, re.IGNORECASE))\n",
        "    has_intersect = bool(re.search(r\"\\bINTERSECT\\b\", sql_query, re.IGNORECASE))\n",
        "    has_union = bool(re.search(r\"\\bUNION\\b\", sql_query, re.IGNORECASE))\n",
        "\n",
        "    # Critério especial para subconsultas com JOIN\n",
        "    has_nested_join = bool(\n",
        "        re.search(r\"\\(SELECT\\b.*?\\bJOIN\\b\", sql_query, re.IGNORECASE | re.DOTALL)\n",
        "    )\n",
        "\n",
        "    # Classificação de dificuldade com base nos critérios do Spider\n",
        "    if has_union:\n",
        "        return \"extra hard\"  # `UNION` é sempre \"extra hard\"\n",
        "    elif has_nested_join or num_nested > 1:\n",
        "        return \"extra hard\"  # Subconsulta com JOIN ou múltiplas subconsultas\n",
        "    elif (\n",
        "        num_select <= 1\n",
        "        and num_where <= 1\n",
        "        and num_group_by == 0\n",
        "        and num_order_by == 0\n",
        "        and num_nested == 0\n",
        "        and num_joins == 0\n",
        "        and not (has_except or has_intersect)\n",
        "    ):\n",
        "        return \"easy\"\n",
        "    elif (\n",
        "        num_select <= 3\n",
        "        and num_where <= 2\n",
        "        and num_group_by <= 1\n",
        "        and num_order_by <= 1\n",
        "        and num_nested == 0\n",
        "        and num_joins <= 1\n",
        "        and not (has_except or has_intersect)\n",
        "    ):\n",
        "        return \"medium\"\n",
        "    elif (\n",
        "        num_group_by > 1\n",
        "        or num_order_by > 1\n",
        "        or num_nested > 0\n",
        "        or num_where > 2\n",
        "        or num_joins > 1\n",
        "        or has_except\n",
        "        or has_intersect\n",
        "    ):\n",
        "        return \"hard\"\n",
        "    else:\n",
        "        return \"extra hard\"\n",
        "\n",
        "  def __process_file(self, file_name):\n",
        "    \"\"\" \"\"\"\n",
        "\n",
        "    with open(os.path.join(DATA_PATH, self.dataset[\"name\"], file_name), 'r') as file:\n",
        "      dataset = json.load(file)\n",
        "\n",
        "      print(f\"Arquivo a ser tratado: {file_name}\\n\\n\")\n",
        "      print(\"Quantidade de amostras no arquivo: \", len(dataset))\n",
        "\n",
        "      qtd_by_language = int(len(dataset) / len(self.dataset['languages']))\n",
        "\n",
        "      print(f\"Quantidade de amostras por idioma: {qtd_by_language}\\n\\n\")\n",
        "\n",
        "      language_indicator = 0\n",
        "      data_indicator = 0\n",
        "\n",
        "      for i, data in enumerate(dataset):\n",
        "        # descobre a complexidade da amostra\n",
        "        data['complexity'] = self.__complexity_discover_of_query(data['query'])\n",
        "\n",
        "        # descobre o idioma da amostra\n",
        "        if data_indicator < qtd_by_language:\n",
        "          data['language'] = self.dataset['languages'][language_indicator]\n",
        "        else:\n",
        "          language_indicator += 1\n",
        "          data_indicator = 0\n",
        "          data['language'] = self.dataset['languages'][language_indicator]\n",
        "\n",
        "        data_indicator += 1\n",
        "\n",
        "      if len(self.dataset['languages']) > 1:\n",
        "          print(\"Amostras da fronteira:\")\n",
        "          print(\n",
        "              f\"* {dataset[qtd_by_language - 1]['language']}: {dataset[qtd_by_language - 1]['question']}\"\n",
        "          )\n",
        "          print(\n",
        "              f\"* {dataset[qtd_by_language]['language']}: {dataset[qtd_by_language]['question']}\"\n",
        "          )\n",
        "\n",
        "      out_file_name = PREFIX_ANNOTATED + file_name\n",
        "\n",
        "      self.__write_dataset_in_file(out_file_name, dataset)\n",
        "\n",
        "      print(f\"\\n\\nArquivo \\\"{out_file_name}\\\" tratado e salvo com sucesso!\\n\")\n",
        "      print(\"=============================================================\\n\")\n",
        "\n",
        "  def __write_dataset_in_file(self, file_name, data):\n",
        "    \"\"\" Escreve o dataset tratado em um arquivo \"\"\"\n",
        "\n",
        "    # cria o diretorio se não exitir\n",
        "    os.makedirs(f\"{DATA_OUTPUT_PATH}\", exist_ok=True)\n",
        "\n",
        "    # reescreve o arquivo com as devidas alterações\n",
        "    with open(f\"{DATA_OUTPUT_PATH}/{file_name}\", 'w') as file:\n",
        "        json.dump(data, file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgJZlosm0HPa"
      },
      "outputs": [],
      "source": [
        "# marker = DatasetMarker(SQL_DATA_INFO[\"spider-en-pt\"])\n",
        "# marker.process()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T37RcD6pxo7_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class DatasetReport:\n",
        "    def __init__(self, dataset, files):\n",
        "        self.dataset = dataset\n",
        "        self.files = files\n",
        "\n",
        "    def __report(self, file_name):\n",
        "        words_in = []\n",
        "        words_out = []\n",
        "\n",
        "        with open(file_name, 'r') as file:\n",
        "            dataset = json.load(file)\n",
        "\n",
        "            print(f\"Quantidade de amostras: {len(dataset)}\")\n",
        "\n",
        "            qtd_easy = 0\n",
        "            qtd_medium = 0\n",
        "            qtd_hard = 0\n",
        "            qtd_extra_hard = 0\n",
        "\n",
        "            for i, data in enumerate(dataset):\n",
        "              if data['difficulty'] == 'easy':\n",
        "                qtd_easy += 1\n",
        "              elif data['difficulty'] == 'medium':\n",
        "                qtd_medium += 1\n",
        "              elif data['difficulty'] == 'hard':\n",
        "                qtd_hard += 1\n",
        "              elif data['difficulty'] == 'extra hard':\n",
        "                qtd_extra_hard += 1\n",
        "\n",
        "              words_in.append(data['count_words_in'])\n",
        "              words_out.append(data['count_words_out'])\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"\\nQuantidade de amostras fáceis: {qtd_easy} = {round((qtd_easy/len(dataset)) * 100, 2)}%\")\n",
        "        print(f\"Quantidade de amostras médias: {qtd_medium} = {round((qtd_medium/len(dataset)) * 100, 2)}%\")\n",
        "        print(f\"Quantidade de amostras difíceis: {qtd_hard} = {round((qtd_hard/len(dataset)) * 100, 2)}%\")\n",
        "        print(f\"Quantidade de amostras extra difíceis: {qtd_extra_hard} = {round((qtd_extra_hard/len(dataset)) * 100, 2)}%\")\n",
        "\n",
        "        print(f\"\\nQuantidade mínima de palavras no input: {np.min(words_in)}\")\n",
        "        print(f\"Quantidade máxima de palavras no input: {np.max(words_in)}\")\n",
        "        print(f\"Quantidade média de palavras no input: {np.mean(words_in)}\")\n",
        "        print(f\"Quantidade total de palavras no input: {np.sum(words_in)}\")\n",
        "        print(f\"Desvio padrão: {np.std(words_in)}\")\n",
        "\n",
        "        print(f\"\\nQuantidade mínima de palavras no output: {np.min(words_out)}\")\n",
        "        print(f\"Quantidade máxima de palavras no output: {np.max(words_out)}\")\n",
        "        print(f\"Quantidade média de palavras no output: {np.mean(words_out)}\")\n",
        "        print(f\"Quantidade total de palavras no output: {np.sum(words_out)}\")\n",
        "        print(f\"Desvio padrão: {np.std(words_out)}\")\n",
        "        print(\"=======================================\\n\\n\")\n",
        "\n",
        "    def report(self):\n",
        "        \"\"\"report\"\"\"\n",
        "        print(\"\\n\\n=======================================\")\n",
        "        print(\"Relatório de processamento do dataset.\")\n",
        "        print(f\"Dataset: {dataset['name']}\")\n",
        "\n",
        "        for file in self.files:\n",
        "          print(f\"\\nArquivo: {file}\")\n",
        "          self.__report(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q8A3aTI0mO4x"
      },
      "outputs": [],
      "source": [
        "from genericpath import exists\n",
        "from tqdm import tqdm\n",
        "import jsonlines\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "class ProcessDataset:\n",
        "  def __init__(self, dataset, train_file, eval_file, dev_file, num_shot=0, code_representation=False):\n",
        "    self.dataset = dataset\n",
        "    self.num_shot = num_shot\n",
        "    self.code_representation = code_representation\n",
        "\n",
        "    self.train_file = train_file\n",
        "    self.eval_file = eval_file\n",
        "    self.dev_file = dev_file\n",
        "\n",
        "    self.nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "    self.nlp_pt = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "  def __def_verifica_anotacao(self):\n",
        "        exists_train = os.path.isfile(os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_ANNOTATED}{self.dataset['train_file']}\"))\n",
        "        exists_eval = os.path.isfile(os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_ANNOTATED}{self.dataset['evaluate_file']}\"))\n",
        "        exists_dev = os.path.isfile(os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_ANNOTATED}{self.dataset['dev_file']}\"))\n",
        "\n",
        "        if exists_train and exists_eval and exists_dev:\n",
        "          return True\n",
        "\n",
        "        return False\n",
        "\n",
        "  def __count_words(self, text, language):\n",
        "        return len(self.nlp_en(text) if language == \"EN\" else self.nlp_pt(text))\n",
        "\n",
        "  def __decode_json_file(\n",
        "        self,\n",
        "        data_file_list,\n",
        "        table_file,\n",
        "        db_folder_path,\n",
        "        db_id_name,\n",
        "        output_name,\n",
        "        is_multiple_turn=False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        @TODO:\n",
        "            1. Colocar o prompt relacionado no arquivo de configuração\n",
        "            2. Colocar as informações dos campos de diferentes fontes de dados no arquivo de configuração\n",
        "        \"\"\"\n",
        "\n",
        "        if table_file.endswith(\".jsonl\"):\n",
        "            tables = jsonlines.open(table_file)\n",
        "            datas = []\n",
        "            for data_file in data_file_list:\n",
        "                datas.extend(jsonlines.open(data_file))\n",
        "\n",
        "        elif table_file.endswith(\".json\"):\n",
        "            with open(table_file) as table:\n",
        "                tables = json.load(table)\n",
        "                datas = []\n",
        "                for data_file in data_file_list:\n",
        "                    with open(data_file) as data:\n",
        "                        datas.extend(json.load(data))\n",
        "        else:\n",
        "            print(\"Unsupported file types\")\n",
        "            raise ValueError(\"Unsupported file types\")\n",
        "\n",
        "        # Primeiro, processe corretamente as tabelas e colunas do db_id\n",
        "        db_dict = {}\n",
        "        for item in tables:\n",
        "            tables = item[\"table_names_original\"]\n",
        "            coloumns = item[\"column_names_original\"][1:]\n",
        "            primary_key = item[\"primary_keys\"]\n",
        "            foreign_keys = item[\"foreign_keys\"]\n",
        "\n",
        "            source = (\n",
        "                item[\"db_id\"] + \" contains tables such as \" + \", \".join(tables) + \". \"\n",
        "            )\n",
        "\n",
        "            for i, name in enumerate(tables):\n",
        "                data = [coloumn[1] for coloumn in coloumns if coloumn[0] == i]\n",
        "                source += (\n",
        "                    \"Table \" + name + \" has columns such as \" + \", \".join(data) + \". \"\n",
        "                )\n",
        "\n",
        "                # get primary key info\n",
        "                for j in range(len(primary_key)):\n",
        "                    if type(primary_key[j]) == int:\n",
        "                        if coloumns[primary_key[j] - 1][0] == i:\n",
        "                            source += (\n",
        "                                coloumns[primary_key[j] - 1][1]\n",
        "                                + \" is the primary key.\"\n",
        "                                + \"\\n\"\n",
        "                            )\n",
        "\n",
        "                    # combination primary key\n",
        "                    elif type(primary_key[j]) == list:\n",
        "                        combine_p = \"The combination of (\"\n",
        "                        keys = []\n",
        "\n",
        "                        for k in range(len(primary_key[j])):\n",
        "                            if coloumns[primary_key[j][k] - 1][0] == i:\n",
        "                                keys.append(coloumns[primary_key[j][k] - 1][1])\n",
        "\n",
        "                        source += (\n",
        "                            combine_p\n",
        "                            + \", \".join(keys)\n",
        "                            + \") are the primary key.\"\n",
        "                            + \"\\n\"\n",
        "                        )\n",
        "                    else:\n",
        "                        print(\"not support type\", type(primary_key[j]))\n",
        "                        continue\n",
        "\n",
        "            # get foreign key info\n",
        "            for key in foreign_keys:\n",
        "                source += (\n",
        "                    \"The \"\n",
        "                    + coloumns[key[0] - 1][1]\n",
        "                    + \" of \"\n",
        "                    + tables[coloumns[key[0] - 1][0]]\n",
        "                    + \" is the foreign key of \"\n",
        "                    + coloumns[key[1] - 1][1]\n",
        "                    + \" of \"\n",
        "                    + tables[coloumns[key[1] - 1][0]]\n",
        "                    + \".\\n\"\n",
        "                )\n",
        "\n",
        "            db_dict[item[\"db_id\"]] = source\n",
        "\n",
        "        res = []\n",
        "        base_instruction = INSTRUCTION_PROMPT\n",
        "\n",
        "        if self.num_shot == 1:\n",
        "            base_instruction = INSTRUCTION_ONE_SHOT_PROMPT\n",
        "\n",
        "        for data in tqdm(datas):\n",
        "            if data[db_id_name] in db_dict.keys():\n",
        "                if is_multiple_turn:  # Múltiplas rodadas\n",
        "                    history = []\n",
        "\n",
        "                    for interaction in data[\"interaction\"]:\n",
        "                        sql_query = interaction[output_name]\n",
        "\n",
        "                        input = INPUT_PROMPT.format(interaction[\"utterance\"])\n",
        "                        context = db_dict[data[db_id_name]]\n",
        "\n",
        "                        input_data = {\n",
        "                            \"db_id\": data[db_id_name],\n",
        "                            \"instruction\": base_instruction.format(\n",
        "                                context\n",
        "                            ),\n",
        "                            \"context\": context,\n",
        "                            \"input\": input,\n",
        "                            \"language\": data[\"language\"],\n",
        "                            \"output\": sql_query,\n",
        "                            \"difficulty\": data[\"complexity\"],\n",
        "                            \"history\": history,\n",
        "                            \"count_words_in\": self.__count_words(input.replace(\"\\n\\n###Response:\", \"\\n\\n###Context:\\n\") + context + \"\\n\\n###Response:\", data[\"language\"]),\n",
        "                            \"count_words_out\": self.__count_words(sql_query, data[\"language\"]),\n",
        "                        }\n",
        "\n",
        "                        res.append(input_data)\n",
        "                        history.append(\n",
        "                            (\n",
        "                                INPUT_PROMPT.format(interaction[\"utterance\"]),\n",
        "                                interaction[output_name],\n",
        "                            )\n",
        "                        )\n",
        "                else:  # Rodada única\n",
        "                    sql_query = data[output_name]\n",
        "\n",
        "                    if self.code_representation:\n",
        "                        db_path = os.path.join(db_folder_path, data[db_id_name])\n",
        "                        sql_file_path = next(\n",
        "                            (\n",
        "                                file\n",
        "                                for file in os.listdir(db_path)\n",
        "                                if file.endswith(\".sql\")\n",
        "                            ),\n",
        "                            None,\n",
        "                        )\n",
        "\n",
        "                        if sql_file_path is None:\n",
        "                            continue  # Encerrar a iteração antecipadamente\n",
        "\n",
        "                        schema_file_path = os.path.join(db_path, sql_file_path)\n",
        "\n",
        "                        with open(schema_file_path, \"r\", encoding=\"utf8\") as file:\n",
        "                            schema_content = file.read()\n",
        "\n",
        "                        create_statements = re.findall(\n",
        "                            r\"CREATE\\s.*?;\", schema_content, re.DOTALL | re.IGNORECASE\n",
        "                        )\n",
        "\n",
        "                        input = INPUT_PROMPT.format(data[\"question\"])\n",
        "\n",
        "                        input_data = {\n",
        "                            \"db_id\": data[db_id_name],\n",
        "                            \"instruction\": INSTRUCTION_PROMPT.format(create_statements),\n",
        "                            \"context\": create_statements,\n",
        "                            \"input\": input,\n",
        "                            \"language\": data[\"language\"],\n",
        "                            \"output\": sql_query,\n",
        "                            \"difficulty\": data[\"complexity\"],\n",
        "                            \"history\": [],\n",
        "                            \"count_words_in\": self.__count_words(input.replace(\"\\n\\n###Response:\", \"\\n\\n###Context:\\n\") + create_statements + \"\\n\\n###Response:\", data[\"language\"]),\n",
        "                            \"count_words_out\": self.__count_words(sql_query, data[\"language\"]),\n",
        "                        }\n",
        "                        res.append(input_data)\n",
        "                    else:\n",
        "                        input = INPUT_PROMPT.format(data[\"question\"])\n",
        "                        context = db_dict[data[db_id_name]]\n",
        "                        input_data = {\n",
        "                            \"db_id\": data[db_id_name],\n",
        "                            \"instruction\": base_instruction.format(\n",
        "                                context\n",
        "                            ),\n",
        "                            \"context\": context,\n",
        "                            \"input\": input,\n",
        "                            \"language\": data[\"language\"],\n",
        "                            \"output\": sql_query,\n",
        "                            \"difficulty\": data[\"complexity\"],\n",
        "                            \"history\": [],\n",
        "                            \"count_words_in\": self.__count_words(input.replace(\"\\n\\n###Response:\", \"\\n\\n###Context:\\n\") + context + \"\\n\\n###Response:\", data[\"language\"]),\n",
        "                            \"count_words_out\": self.__count_words(sql_query, data[\"language\"]),\n",
        "                        }\n",
        "                        res.append(input_data)\n",
        "        return res\n",
        "\n",
        "  def process(self, report=True):\n",
        "        \"\"\"process\"\"\"\n",
        "        print(\"Iniciando processador do dataset.\")\n",
        "\n",
        "        if not self.__def_verifica_anotacao():\n",
        "            print(\"Dataset ainda não foi anotado. Efetuando anotação...\")\n",
        "            marker = DatasetMarker(self.dataset)\n",
        "            marker.process()\n",
        "\n",
        "        print(\"Dataset devidamente anotado.\")\n",
        "\n",
        "        print(\"\\nProcessando o dataset...\")\n",
        "\n",
        "        train_data = []\n",
        "        eval_data = []\n",
        "        dev_data = []\n",
        "\n",
        "        for data_info in SQL_DATA_INFO.values():\n",
        "            if data_info[\"name\"] != DATASET_TARGET:\n",
        "                continue\n",
        "\n",
        "            tfile = data_info[\"train_file\"]\n",
        "            efile = data_info[\"evaluate_file\"]\n",
        "            dfile = data_info[\"dev_file\"]\n",
        "\n",
        "            train_data_file_list = [\n",
        "                os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_ANNOTATED}{tfile}\")\n",
        "            ]\n",
        "\n",
        "            train_data.extend(\n",
        "                self.__decode_json_file(\n",
        "                    data_file_list=train_data_file_list,\n",
        "                    table_file=os.path.join(\n",
        "                        DATA_PATH,\n",
        "                        data_info[\"name\"],\n",
        "                        data_info[\"train_tables\"],\n",
        "                    ),\n",
        "                    db_folder_path=os.path.join(\n",
        "                        DATA_PATH,\n",
        "                        data_info[\"name\"],\n",
        "                        \"database\",\n",
        "                    ),\n",
        "                    db_id_name=data_info[\"db_id_name\"],\n",
        "                    output_name=data_info[\"output_name\"],\n",
        "                    is_multiple_turn=data_info[\"is_multiple_turn\"],\n",
        "                )\n",
        "            )\n",
        "\n",
        "            eval_data_file_list = [\n",
        "                os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_ANNOTATED}{efile}\")\n",
        "            ]\n",
        "\n",
        "            eval_data.extend(\n",
        "                self.__decode_json_file(\n",
        "                    data_file_list=eval_data_file_list,\n",
        "                    table_file=os.path.join(\n",
        "                        DATA_PATH,\n",
        "                        data_info[\"name\"],\n",
        "                        data_info[\"eval_tables\"],\n",
        "                    ),\n",
        "                    db_folder_path=os.path.join(\n",
        "                        DATA_PATH,\n",
        "                        data_info[\"name\"],\n",
        "                        \"database\",\n",
        "                    ),\n",
        "                    db_id_name=data_info[\"db_id_name\"],\n",
        "                    output_name=data_info[\"output_name\"],\n",
        "                    is_multiple_turn=data_info[\"is_multiple_turn\"],\n",
        "                )\n",
        "            )\n",
        "\n",
        "            dev_data_file_list = [\n",
        "                os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_ANNOTATED}{dfile}\")\n",
        "            ]\n",
        "\n",
        "            dev_data.extend(\n",
        "                self.__decode_json_file(\n",
        "                    data_file_list=dev_data_file_list,\n",
        "                    table_file=os.path.join(\n",
        "                        DATA_PATH,\n",
        "                        data_info[\"name\"],\n",
        "                        data_info[\"dev_tables\"],\n",
        "                    ),\n",
        "                    db_folder_path=os.path.join(\n",
        "                        DATA_PATH,\n",
        "                        data_info[\"name\"],\n",
        "                        \"database\",\n",
        "                    ),\n",
        "                    db_id_name=data_info[\"db_id_name\"],\n",
        "                    output_name=data_info[\"output_name\"],\n",
        "                    is_multiple_turn=data_info[\"is_multiple_turn\"],\n",
        "                )\n",
        "            )\n",
        "\n",
        "        if train_data:\n",
        "            with open(self.train_file, \"w\", encoding=\"utf-8\") as s:\n",
        "                json.dump(train_data, s, indent=4, ensure_ascii=False)\n",
        "\n",
        "        if eval_data:\n",
        "            with open(self.eval_file, \"w\", encoding=\"utf-8\") as s:\n",
        "                json.dump(eval_data, s, indent=4, ensure_ascii=False)\n",
        "\n",
        "        if dev_data:\n",
        "            with open(self.dev_file, \"w\", encoding=\"utf-8\") as s:\n",
        "                json.dump(dev_data, s, indent=4, ensure_ascii=False)\n",
        "\n",
        "        if not train_data and not eval_data and not dev_data:\n",
        "            print(\"Nenhum dataset foi processado.\")\n",
        "            return\n",
        "\n",
        "        if report:\n",
        "            print(\"Dataset processado com sucesso!\")\n",
        "            reporter = DatasetReport(self.dataset, [self.train_file, self.eval_file, self.dev_file])\n",
        "            reporter.report()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "1oFmlaKflxmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d001a2-2020-4fc7-ae69-9955bb524bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando processamento do dataset spider-en\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando processador do dataset.\n",
            "Dataset devidamente anotado.\n",
            "\n",
            "Processando o dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7000/7000 [06:01<00:00, 19.36it/s]\n",
            "100%|██████████| 1659/1659 [01:45<00:00, 15.73it/s]\n",
            "100%|██████████| 1034/1034 [00:41<00:00, 24.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset processado com sucesso!\n",
            "\n",
            "\n",
            "=======================================\n",
            "Relatório de processamento do dataset.\n",
            "Dataset: spider-en\n",
            "\n",
            "Arquivo: /content/drive/MyDrive/Mestrado/Projeto/data/spider-en-ajusted/processed-train_spider.json\n",
            "Quantidade de amostras: 7000\n",
            "\n",
            "Quantidade de amostras fáceis: 1543 = 22.04%\n",
            "Quantidade de amostras médias: 3808 = 54.4%\n",
            "Quantidade de amostras difíceis: 1485 = 21.21%\n",
            "Quantidade de amostras extra difíceis: 164 = 2.34%\n",
            "\n",
            "Quantidade mínima de palavras no input: 73\n",
            "Quantidade máxima de palavras no input: 1240\n",
            "Quantidade média de palavras no input: 272.45285714285717\n",
            "Quantidade total de palavras no input: 1907170\n",
            "Desvio padrão: 199.48813586020498\n",
            "\n",
            "Quantidade mínima de palavras no output: 4\n",
            "Quantidade máxima de palavras no output: 112\n",
            "Quantidade média de palavras no output: 20.78757142857143\n",
            "Quantidade total de palavras no output: 145513\n",
            "Desvio padrão: 12.224081144050318\n",
            "=======================================\n",
            "\n",
            "\n",
            "\n",
            "Arquivo: /content/drive/MyDrive/Mestrado/Projeto/data/spider-en-ajusted/processed-train_others.json\n",
            "Quantidade de amostras: 1659\n",
            "\n",
            "Quantidade de amostras fáceis: 545 = 32.85%\n",
            "Quantidade de amostras médias: 298 = 17.96%\n",
            "Quantidade de amostras difíceis: 816 = 49.19%\n",
            "Quantidade de amostras extra difíceis: 0 = 0.0%\n",
            "\n",
            "Quantidade mínima de palavras no input: 125\n",
            "Quantidade máxima de palavras no input: 602\n",
            "Quantidade média de palavras no input: 342.7528631705847\n",
            "Quantidade total de palavras no input: 568627\n",
            "Desvio padrão: 123.73516477927183\n",
            "\n",
            "Quantidade mínima de palavras no output: 5\n",
            "Quantidade máxima de palavras no output: 99\n",
            "Quantidade média de palavras no output: 37.88065099457504\n",
            "Quantidade total de palavras no output: 62844\n",
            "Desvio padrão: 19.241405538546555\n",
            "=======================================\n",
            "\n",
            "\n",
            "\n",
            "Arquivo: /content/drive/MyDrive/Mestrado/Projeto/data/spider-en-ajusted/processed-dev.json\n",
            "Quantidade de amostras: 1034\n",
            "\n",
            "Quantidade de amostras fáceis: 246 = 23.79%\n",
            "Quantidade de amostras médias: 597 = 57.74%\n",
            "Quantidade de amostras difíceis: 157 = 15.18%\n",
            "Quantidade de amostras extra difíceis: 34 = 3.29%\n",
            "\n",
            "Quantidade mínima de palavras no input: 93\n",
            "Quantidade máxima de palavras no input: 481\n",
            "Quantidade média de palavras no input: 203.80947775628627\n",
            "Quantidade total de palavras no input: 210739\n",
            "Desvio padrão: 96.26225193752306\n",
            "\n",
            "Quantidade mínima de palavras no output: 4\n",
            "Quantidade máxima de palavras no output: 77\n",
            "Quantidade média de palavras no output: 20.676982591876207\n",
            "Quantidade total de palavras no output: 21380\n",
            "Desvio padrão: 12.317138764187648\n",
            "=======================================\n",
            "\n",
            "\n",
            "Iniciando processamento do dataset spider-en com One Shot Learning\n",
            "Iniciando processador do dataset.\n",
            "Dataset devidamente anotado.\n",
            "\n",
            "Processando o dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7000/7000 [05:54<00:00, 19.72it/s]\n",
            "100%|██████████| 1659/1659 [01:42<00:00, 16.19it/s]\n",
            "100%|██████████| 1034/1034 [00:42<00:00, 24.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finalizado processamento do Dataset!\n"
          ]
        }
      ],
      "source": [
        "# if __name__ == \"__main__\":\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument(\n",
        "#     \"--code_representation\", help=\"Enable code representation\", default=False\n",
        "# )\n",
        "# args = parser.parse_args()\n",
        "\n",
        "dataset = SQL_DATA_INFO[DATASET_TARGET]\n",
        "\n",
        "print(f\"Iniciando processamento do dataset {DATASET_TARGET}\")\n",
        "\n",
        "\n",
        "train_file = os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_PROCESSED}{dataset['train_file']}\")\n",
        "eval_file = os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_PROCESSED}{dataset['evaluate_file']}\")\n",
        "dev_file = os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_PROCESSED}{dataset['dev_file']}\")\n",
        "\n",
        "process = ProcessDataset(\n",
        "    dataset=dataset,\n",
        "    train_file=train_file,\n",
        "    eval_file=eval_file,\n",
        "    dev_file=dev_file,\n",
        "    code_representation=False, # args.code_representation,\n",
        ")\n",
        "process.process()\n",
        "\n",
        "print(f\"Iniciando processamento do dataset {DATASET_TARGET} com One Shot Learning\")\n",
        "\n",
        "onse_shot_train_file = os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_ONE_SHOT}{dataset['train_file']}\")\n",
        "onse_shot_eval_file = os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_ONE_SHOT}{dataset['evaluate_file']}\")\n",
        "onse_shot_dev_file = os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_ONE_SHOT}{dataset['dev_file']}\")\n",
        "\n",
        "process = ProcessDataset(\n",
        "    dataset=dataset,\n",
        "    train_file=onse_shot_train_file,\n",
        "    eval_file=onse_shot_eval_file,\n",
        "    dev_file=onse_shot_dev_file,\n",
        "    num_shot=1,\n",
        "    code_representation=False, # args.code_representation,\n",
        ")\n",
        "process.process(report=False)\n",
        "\n",
        "print(f\"Finalizado processamento do Dataset!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgtIYmUuMT_y"
      },
      "source": [
        "###FINETUNNING T5-SMALL\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YXojb9i2MgJF",
        "outputId": "54737b60-6316-4305-90fe-1c8e55b4b7da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from google.colab import userdata\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import (\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    EarlyStoppingCallback,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    TrainerCallback\n",
        ")\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "from datasets import DatasetDict\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcoxZo84npyC"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path, language=None):\n",
        "    with open(path, 'r', encoding='utf-8') as arquivo:\n",
        "        data = pd.read_json(arquivo)\n",
        "        if language is None:\n",
        "            return data\n",
        "        else:\n",
        "            # Filtra os dados onde 'language' é igual ao parâmetro fornecido\n",
        "            filtered_data = data[data['language'] == language]\n",
        "            return filtered_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f16577dsdX67"
      },
      "outputs": [],
      "source": [
        "# transforma os dataframes em Dataset para a devida utilização no treinamento\n",
        "dataset_dict = {\n",
        "    'train': Dataset.from_pandas(\n",
        "        load_dataset(\n",
        "            os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_PROCESSED}train_spider.json\"), language=LANGUAGE_TARGET\n",
        "        )\n",
        "    ),\n",
        "    'validation': Dataset.from_pandas(\n",
        "        load_dataset(\n",
        "            os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_PROCESSED}train_others.json\"), language=LANGUAGE_TARGET\n",
        "        )\n",
        "    ),\n",
        "    'test': Dataset.from_pandas(\n",
        "        load_dataset(\n",
        "            os.path.join(DATA_OUTPUT_PATH, f\"{PREFIX_PROCESSED}dev.json\"), language=LANGUAGE_TARGET\n",
        "        )\n",
        "    ),\n",
        "}\n",
        "dataset = DatasetDict(dataset_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-RYcrhZKf140"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YQ0rLDcASZ7"
      },
      "outputs": [],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "e78157dd4935451e8b113d24fa449255",
            "179582a7b5ba4c619fa7b1350c393296",
            "d97459b59bda47d290b7b7ee01b895ca",
            "8f08f2b48eff45878ff680f82d7740bb",
            "7fcc46c39bf64fe3a1bfe7e0131273f7",
            "96c82fefca51416e825d139ea48809ca",
            "cbac24a409604584a2500df16664a957",
            "5d90c469f65b4cd5970badce15216ba7",
            "40c68c11fa594227bcd0171ea6051ca0",
            "6ad73f37af6744fea95b99c11d5f92b4",
            "a5feb3710c9a49b6ac70c8c12ca42704",
            "6bc06334bd7d44f4bc1bf097cfa4da71",
            "ece541d7edbe4ddfa9387c165d571781",
            "b4b5d86296824719a556e52a127d83d6",
            "1f59c942836f46cf98439de681fe0549",
            "bf3cf2dcf25c467d8f4ce909c0c4a466",
            "c16839ac362a4129925da060d9e72143",
            "a598538d2912418e8309a71af18b98e1",
            "3d5a66233fe341789d6be504d48ab8ec",
            "343130836cb6408a8cfbc627537651bd",
            "ebc108c1755748de94847e0fbbdd25c5",
            "6b6ab5c47eec45ed9b0966f9f2bfd2fd",
            "b671ed72e2954a5ba371057a4404fb98",
            "beb8c1bb542145a9ae3e3658bbcf08ce",
            "dc7c5032bb3040768ba06bf762be59db",
            "8f6e9165cedf4be4a459c11686b8bab5",
            "2be14612767343ee88e8cccba644b127",
            "1b48285e1d1549e7aacd5346bceeb99e",
            "9a5c982507ee4afe9503ba170be47869",
            "bc6927321a144298a96957a8ec992159",
            "7e0fa77255de4cf88472fdecbc77ef26",
            "1009edc48d4240a2b0c3f01a3abb6eaf",
            "397117f2debe450ab8878e96656c1884",
            "9213a19a6bed41f78f510d3c5c30b511",
            "e2d13e60781246c9baa70f7dd92ce313",
            "f6d9a2f3e4e34bcbab4a794596f405a4",
            "9459348d115247bcad2bf4f7d85c7b40",
            "2e6470a5b2704f818dab14ca1e856d34",
            "5732b90931484cdab9354064a6e7ee60",
            "d7b5c047fb7f4415bcc5af2816e1405f",
            "05199515c5104231a2b3dbf9c606b259",
            "33114afa3b9b4d188466e24fbb0803df",
            "fec53d78d51848d2879625a4424d97e6",
            "40813ed5846549899d7b8960cecb6a52",
            "02e19e32c2d0441daef15d4dc62bea90",
            "88a8723c067c414da2a423c4042202fe",
            "ece980062e1a4da1ab037115f12c84ad",
            "e03e061799b84a7c87ffb4c47dae6257",
            "adecc803eb4a462d99e9084d6b510303",
            "405c8ace55714602af43d14aaefa1fbe",
            "dce20679fe2c40ad925da68b92f9d8bd",
            "c2f2ecf4475f452185c9416d12eaf843",
            "290c46e8cdfc4d2692ff97d865992a27",
            "11cd61678c464147b70121c85f6ae078",
            "91d0dc50055f4eefb818ab5b521eb625",
            "1a6797ad7e68454d997dc01ffe337b09",
            "b81e4afc639d40ef88a26d7d689b749c",
            "82e10eddede14a48864538b4edad83c1",
            "ac173113177c4e0a90e51db311d694ed",
            "b5e9b76f5f7e4ec9943b85dde4b18123",
            "4006cf7e1f5a452e9d852ff720123373",
            "3d6da37c89fa46f080b2d6312a682eb0",
            "b74a174cf7734f3d8ed31e08811cfa58",
            "576d69a8b37d46d6b879d2b7526df8cc",
            "85243a106e074caf93098ce450d8491b",
            "b8c7de9e5336482dba63e8259c46bed7",
            "acb927270ea4433bb9921b11e4fc5901",
            "56ec1d1c7c0e4046b1904ecc04772dd3",
            "67ff9f24d7e846339f7ba6e3b6330247",
            "adcb3de69e2c4117bc1d2c1a22318fb8",
            "aebc48eb91874c379b577860f76ca67d",
            "abbd8a80b05d452db14243a6b70599a0",
            "7fa84b62ad9b498788f414ec69c18193",
            "fdb3531c247a405bae8a6c3f1713782b",
            "307fff7d3111442d861dd5f9f0568e94",
            "dfdcb288d2da432abafba37d334aa56c",
            "a751110fc4d149039d053fa407a7852b"
          ]
        },
        "collapsed": true,
        "id": "4XX6NA7KYcNu",
        "outputId": "17fe1c16-8691-4bdd-87d4-eddc89e12152"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e78157dd4935451e8b113d24fa449255"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bc06334bd7d44f4bc1bf097cfa4da71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b671ed72e2954a5ba371057a4404fb98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9213a19a6bed41f78f510d3c5c30b511"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02e19e32c2d0441daef15d4dc62bea90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a6797ad7e68454d997dc01ffe337b09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acb927270ea4433bb9921b11e4fc5901"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 2. Inicializar o modelo e tokenizer do T5-small\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "6fb871efa5dc468aa2f67a07671f8dbc",
            "d402ecd177df4299a940ef32a70b83f7",
            "eee898ab9c6e42a4b87a3d622eddeba7",
            "4181b213f0a44692aa7c023726d7b224",
            "4ac12a4e0c594d448b0c3b13d1063419",
            "574aa762e7ed4c5bbd3b95040ff4b2b1",
            "cd4998c9a914465fb0e30515de2766a1",
            "8f1aa7ad2fd34a53b8c6110aab800f96",
            "cd07aba79680460099ad856e2491ed13",
            "15974d2f574c4d9dbb77672d79805852",
            "d2bb484749974e4da363ded73066b553",
            "fcf29272de2f4c84a972ca8406a4a3dc",
            "e162e2ebe97f469389a74c1fb7f94440",
            "1135beb18d22416d86e06a7f426a4aa0",
            "c59d611dc3d94c09abce18f8b7223edd",
            "b2fa3531d9b94280b0664e1861528f1f",
            "c1661ca9f0af43db8b8392cefcec97b0",
            "7685399ab03141f0ac4ae57942f22183",
            "933b1ea13b2a4c4b9e0d1a033157cc1f",
            "911fabd4469e4623a8e58b4b1a149a84",
            "1c7d78fb63f543b982afcf5045b6cc76",
            "0fb0b2a69969401b85bba3ff7de7089d",
            "5124cf315bd2473bbdd618980d156b18",
            "1d727fef53f646acaebc7e924e203ce1",
            "a5250666ff834257abdde50d53ad1618",
            "1a5b79e74dcb48d58503d3e402cd946b",
            "ae4218a19b1841188c3e21484d3b15fe",
            "bf21ade34f67432bbe4771327d29643c",
            "309d2479ebb84e8a972d606b9a845a4c",
            "4f822fef87964b7abd29ef673d5ec567",
            "7409a6b0043e4c5faa60fe63ad520d17",
            "887b07e46de64f96b3f53ef117aca20b",
            "8e672ebe4bab46aa8cced56608ca5575"
          ]
        },
        "id": "D4JA0T-nlgqN",
        "outputId": "9079d259-fb63-4051-9dd4-5aa56cf88b92"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fb871efa5dc468aa2f67a07671f8dbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1659 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcf29272de2f4c84a972ca8406a4a3dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1034 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5124cf315bd2473bbdd618980d156b18"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 3. Processar o dataset\n",
        "def preprocess_data(examples):\n",
        "    inputs = [\n",
        "        # ajusta para o t5 invertendo o posicionamento do contexto com o input\n",
        "        input.replace(\"\\n\\n###Response:\", \"\\n\\n###Context:\\n\") + context + \"\\n\\n###Response:\"\n",
        "        for context, input in zip(examples['context'], examples['input'])\n",
        "    ]\n",
        "    targets = [sql for sql in examples['output']]\n",
        "\n",
        "    # Tokenize inputs e targets\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\").input_ids\n",
        "\n",
        "    model_inputs['labels'] = labels\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "# Aplicar o preprocessamento\n",
        "tokenized_datasets = dataset.map(\n",
        "    preprocess_data,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bu2VWd8BSVi"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "8b057b986432486eab0e1eeccca3820a",
            "56a26280a4af4b599beb415441fa32e5",
            "ea5c327fbee34231bb2ee016ba203ba5",
            "812eaab0bc7a41c5a933dcf01f007ebf",
            "dbfc1e2a950f4ed88c5741bff279f331",
            "7f5f7669d96e4a47b6b5f97458364229",
            "adb19df799dd48f6904973b1c4dc0a3d",
            "0dc6ba9917404456987b360d995ffbb1",
            "7195d60d0dab423091576fbe35318e71",
            "66d3af670e5d4d61b20a149a1cc89f33",
            "b1edfdc00aa442adb956fcce7dfcf5c8"
          ]
        },
        "collapsed": true,
        "id": "tGhLfjHklvuf",
        "outputId": "b0a388b9-a35f-4f75-e972-e14380af0efe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b057b986432486eab0e1eeccca3820a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "# 4. Definir as métricas de avaliação\n",
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Ensure predictions and labels are within the allowable range\n",
        "    predictions = np.clip(predictions, a_min=0, a_max=tokenizer.vocab_size - 1)\n",
        "    labels = np.clip(labels, a_min=0, a_max=tokenizer.vocab_size - 1)\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = ['\\n'.join(nltk.sent_tokenize(label_.strip())) for label_ in decoded_labels]\n",
        "\n",
        "    # print('\\n', decoded_preds)\n",
        "    # print('\\n', decoded_labels)\n",
        "\n",
        "    result = rouge.compute(predictions=decoded_preds,\n",
        "                            references=decoded_labels, use_stemmer=True)\n",
        "\n",
        "    # print('\\n', result)\n",
        "\n",
        "    result = {key: value for key, value in result.items()}\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result['gen_len'] = np.mean(prediction_lens)\n",
        "    return {k: round(v, 4) for k, v in result.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHoDNO5zSWAQ"
      },
      "outputs": [],
      "source": [
        "class SaveModelByEpochCallback(TrainerCallback):\n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        if SHOULD_SAVE_EPOCH:\n",
        "            epoch = int(state.epoch)\n",
        "\n",
        "            output_dir_epoch = os.path.join(args.output_dir, \"epochs\", f\"epoch-{epoch}\")\n",
        "\n",
        "            os.makedirs(output_dir_epoch, exist_ok=True)\n",
        "\n",
        "            # print(kwargs)\n",
        "\n",
        "            kwargs['model'].save_pretrained(output_dir_epoch)\n",
        "            kwargs['processing_class'].save_pretrained(output_dir_epoch)\n",
        "\n",
        "            print(f\"Modelo da época {epoch} salvo em {output_dir_epoch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC5DmksZlz81"
      },
      "outputs": [],
      "source": [
        "# 5. Definir os argumentos de treinamento\n",
        "logging_eval_steps = len(tokenized_datasets['train']) // BATCH_SIZE\n",
        "\n",
        "train_args = Seq2SeqTrainingArguments(\n",
        "      output_dir=OUTPUT_MODEL,\n",
        "      num_train_epochs=NUM_EPOCHS,\n",
        "      learning_rate=1e-5, #5.6e-5\n",
        "      per_device_train_batch_size=BATCH_SIZE,\n",
        "      per_device_eval_batch_size=BATCH_SIZE,\n",
        "      weight_decay=0.01,\n",
        "      eval_steps=logging_eval_steps,\n",
        "      logging_steps=logging_eval_steps,\n",
        "      eval_strategy='epoch',\n",
        "      predict_with_generate=True,\n",
        "      report_to=\"none\",\n",
        "      save_total_limit=1,\n",
        "      save_strategy='epoch',\n",
        "      load_best_model_at_end=True,\n",
        "      metric_for_best_model='rougeL',\n",
        "      greater_is_better=True,\n",
        "      push_to_hub=False,\n",
        "      fp16=USE_FP16\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-ocjQMaBl9oF",
        "outputId": "f83af1af-7932-46ee-a338-47d9e7320ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7000' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7000/7000 1:11:06, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>7.807600</td>\n",
              "      <td>1.738310</td>\n",
              "      <td>0.111000</td>\n",
              "      <td>0.041700</td>\n",
              "      <td>0.101800</td>\n",
              "      <td>0.101800</td>\n",
              "      <td>7.912000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.221400</td>\n",
              "      <td>0.920400</td>\n",
              "      <td>0.344800</td>\n",
              "      <td>0.147900</td>\n",
              "      <td>0.320900</td>\n",
              "      <td>0.321300</td>\n",
              "      <td>18.920400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.458200</td>\n",
              "      <td>0.808187</td>\n",
              "      <td>0.341000</td>\n",
              "      <td>0.150700</td>\n",
              "      <td>0.319200</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>18.447300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.296400</td>\n",
              "      <td>0.767738</td>\n",
              "      <td>0.358900</td>\n",
              "      <td>0.163100</td>\n",
              "      <td>0.335800</td>\n",
              "      <td>0.335700</td>\n",
              "      <td>18.346600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.256600</td>\n",
              "      <td>0.761554</td>\n",
              "      <td>0.362900</td>\n",
              "      <td>0.170700</td>\n",
              "      <td>0.340400</td>\n",
              "      <td>0.340300</td>\n",
              "      <td>18.065700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.238500</td>\n",
              "      <td>0.753485</td>\n",
              "      <td>0.370200</td>\n",
              "      <td>0.178700</td>\n",
              "      <td>0.346200</td>\n",
              "      <td>0.346300</td>\n",
              "      <td>18.215800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.228200</td>\n",
              "      <td>0.753689</td>\n",
              "      <td>0.380800</td>\n",
              "      <td>0.183000</td>\n",
              "      <td>0.353400</td>\n",
              "      <td>0.353800</td>\n",
              "      <td>18.326700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.220300</td>\n",
              "      <td>0.752394</td>\n",
              "      <td>0.386300</td>\n",
              "      <td>0.190800</td>\n",
              "      <td>0.358800</td>\n",
              "      <td>0.358800</td>\n",
              "      <td>18.305000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.217300</td>\n",
              "      <td>0.751012</td>\n",
              "      <td>0.386500</td>\n",
              "      <td>0.191900</td>\n",
              "      <td>0.359500</td>\n",
              "      <td>0.359700</td>\n",
              "      <td>18.305000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.214700</td>\n",
              "      <td>0.750462</td>\n",
              "      <td>0.388700</td>\n",
              "      <td>0.191900</td>\n",
              "      <td>0.360800</td>\n",
              "      <td>0.361000</td>\n",
              "      <td>18.342400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='166' max='166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [166/166 01:35]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "***Finetunning Complete!***\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "torch.cuda.empty_cache() # limpa o cache do CUDA\n",
        "\n",
        "# model_path = os.path.join(MODELS_PATH, f'{MODEL}_{DATASET_TARGET}')\n",
        "# output_dir = f'{TRAINNING_PATH}/{MODEL}_{DATASET_TARGET}'\n",
        "\n",
        "os.makedirs(OUTPUT_MODEL, exist_ok=True)\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "train_encoded_dataset = tokenized_datasets[\"train\"]\n",
        "validation_encoded_dataset = tokenized_datasets[\"validation\"]\n",
        "\n",
        "# 6. Inicializar o Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=train_args,\n",
        "    train_dataset=train_encoded_dataset,\n",
        "    eval_dataset=validation_encoded_dataset,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        "    callbacks=[\n",
        "        EarlyStoppingCallback(\n",
        "            early_stopping_patience=5\n",
        "        ),\n",
        "        SaveModelByEpochCallback()\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 7. Iniciar o treinamento\n",
        "if os.path.exists(OUTPUT_MODEL) and len(os.listdir(OUTPUT_MODEL)) > 0:\n",
        "    trainer.train(resume_from_checkpoint=True)\n",
        "else:\n",
        "    trainer.train()\n",
        "\n",
        "trainer.evaluate()\n",
        "\n",
        "# 8. Salvar o modelo fine-tuned\n",
        "trainer.save_model(OUTPUT_MODEL)\n",
        "\n",
        "print('\\n\\n***Finetunning Complete!***')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvHd5G6OfZWl"
      },
      "source": [
        "**Testa o modelo treinado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQpK3t3-fYMf"
      },
      "outputs": [],
      "source": [
        "def use_ajusted_model(model_path, text):\n",
        "  # Carregar o tokenizer\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "  # Carregar o modelo\n",
        "  model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "  input_ids = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\").input_ids\n",
        "\n",
        "  # Gerar a saída\n",
        "  output_ids = model.generate(input_ids, max_new_tokens=128)\n",
        "\n",
        "  # Decodificar a saída\n",
        "  saida = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "  return saida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sqPRxN20VB3"
      },
      "outputs": [],
      "source": [
        "type(dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0KS4OR9EMhQ"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Prediction(BaseModel):\n",
        "    db_id: str\n",
        "    difficulty: Literal[\"easy\", \"medium\", \"hard\", \"extra hard\"]\n",
        "    instruction: str\n",
        "    nl: str\n",
        "    sql_expected: str\n",
        "    sql_predicted: str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zblvbOJ6w0i4",
        "outputId": "d3c1c30d-088f-4b4f-9745-88fc41d66eab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gerando Predições...:  49%|\u001b[31m████▉     \u001b[0m| 507/1034 [18:11<18:29,  2.11s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (963 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  49%|\u001b[31m████▉     \u001b[0m| 508/1034 [18:16<24:14,  2.76s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  49%|\u001b[31m████▉     \u001b[0m| 509/1034 [18:20<27:29,  3.14s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  49%|\u001b[31m████▉     \u001b[0m| 510/1034 [18:22<24:19,  2.79s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (957 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  49%|\u001b[31m████▉     \u001b[0m| 511/1034 [18:24<22:06,  2.54s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  50%|\u001b[31m████▉     \u001b[0m| 512/1034 [18:27<24:35,  2.83s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (961 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  50%|\u001b[31m████▉     \u001b[0m| 513/1034 [18:32<28:57,  3.34s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  50%|\u001b[31m████▉     \u001b[0m| 514/1034 [18:34<25:58,  3.00s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (960 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  50%|\u001b[31m████▉     \u001b[0m| 515/1034 [18:36<23:47,  2.75s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  50%|\u001b[31m████▉     \u001b[0m| 516/1034 [18:39<24:04,  2.79s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  50%|\u001b[31m█████     \u001b[0m| 517/1034 [18:42<23:34,  2.74s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  50%|\u001b[31m█████     \u001b[0m| 518/1034 [18:44<23:37,  2.75s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  50%|\u001b[31m█████     \u001b[0m| 519/1034 [18:47<22:43,  2.65s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  50%|\u001b[31m█████     \u001b[0m| 520/1034 [18:49<22:07,  2.58s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  50%|\u001b[31m█████     \u001b[0m| 521/1034 [18:51<20:39,  2.42s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (960 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  50%|\u001b[31m█████     \u001b[0m| 522/1034 [18:53<19:29,  2.28s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (960 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  51%|\u001b[31m█████     \u001b[0m| 523/1034 [18:56<19:41,  2.31s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  51%|\u001b[31m█████     \u001b[0m| 524/1034 [19:00<24:42,  2.91s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  51%|\u001b[31m█████     \u001b[0m| 525/1034 [19:03<25:39,  3.02s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  51%|\u001b[31m█████     \u001b[0m| 526/1034 [19:06<26:27,  3.13s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (969 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  51%|\u001b[31m█████     \u001b[0m| 527/1034 [19:10<26:35,  3.15s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  51%|\u001b[31m█████     \u001b[0m| 528/1034 [19:13<27:23,  3.25s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  51%|\u001b[31m█████     \u001b[0m| 529/1034 [19:17<28:08,  3.34s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  51%|\u001b[31m█████▏    \u001b[0m| 530/1034 [19:19<25:35,  3.05s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  51%|\u001b[31m█████▏    \u001b[0m| 531/1034 [19:23<27:03,  3.23s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  51%|\u001b[31m█████▏    \u001b[0m| 532/1034 [19:25<24:52,  2.97s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  52%|\u001b[31m█████▏    \u001b[0m| 533/1034 [19:28<25:36,  3.07s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (979 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  52%|\u001b[31m█████▏    \u001b[0m| 534/1034 [19:31<24:18,  2.92s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (984 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  52%|\u001b[31m█████▏    \u001b[0m| 535/1034 [19:34<23:28,  2.82s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  52%|\u001b[31m█████▏    \u001b[0m| 536/1034 [19:36<22:51,  2.75s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  52%|\u001b[31m█████▏    \u001b[0m| 537/1034 [19:39<22:01,  2.66s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (966 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  52%|\u001b[31m█████▏    \u001b[0m| 538/1034 [19:43<26:06,  3.16s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  52%|\u001b[31m█████▏    \u001b[0m| 539/1034 [19:46<25:27,  3.09s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (974 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  52%|\u001b[31m█████▏    \u001b[0m| 540/1034 [19:50<27:20,  3.32s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  52%|\u001b[31m█████▏    \u001b[0m| 541/1034 [19:54<29:50,  3.63s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  52%|\u001b[31m█████▏    \u001b[0m| 542/1034 [19:59<32:58,  4.02s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (986 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  53%|\u001b[31m█████▎    \u001b[0m| 543/1034 [20:02<29:46,  3.64s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  53%|\u001b[31m█████▎    \u001b[0m| 544/1034 [20:05<27:41,  3.39s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  53%|\u001b[31m█████▎    \u001b[0m| 545/1034 [20:08<28:03,  3.44s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  53%|\u001b[31m█████▎    \u001b[0m| 546/1034 [20:11<27:36,  3.39s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  53%|\u001b[31m█████▎    \u001b[0m| 547/1034 [20:15<27:45,  3.42s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (966 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  53%|\u001b[31m█████▎    \u001b[0m| 548/1034 [20:18<27:16,  3.37s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  53%|\u001b[31m█████▎    \u001b[0m| 549/1034 [20:21<27:12,  3.37s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  53%|\u001b[31m█████▎    \u001b[0m| 550/1034 [20:26<29:32,  3.66s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  53%|\u001b[31m█████▎    \u001b[0m| 551/1034 [20:30<30:01,  3.73s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  53%|\u001b[31m█████▎    \u001b[0m| 552/1034 [20:33<28:59,  3.61s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (969 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  53%|\u001b[31m█████▎    \u001b[0m| 553/1034 [20:36<28:12,  3.52s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  54%|\u001b[31m█████▎    \u001b[0m| 554/1034 [20:41<30:41,  3.84s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  54%|\u001b[31m█████▎    \u001b[0m| 555/1034 [20:44<29:53,  3.74s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  54%|\u001b[31m█████▍    \u001b[0m| 556/1034 [20:47<26:41,  3.35s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  54%|\u001b[31m█████▍    \u001b[0m| 557/1034 [20:49<24:19,  3.06s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  54%|\u001b[31m█████▍    \u001b[0m| 558/1034 [20:52<22:42,  2.86s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  54%|\u001b[31m█████▍    \u001b[0m| 559/1034 [20:55<23:44,  3.00s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  54%|\u001b[31m█████▍    \u001b[0m| 560/1034 [20:58<24:26,  3.09s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  54%|\u001b[31m█████▍    \u001b[0m| 561/1034 [21:02<24:49,  3.15s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  54%|\u001b[31m█████▍    \u001b[0m| 562/1034 [21:05<25:45,  3.28s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  54%|\u001b[31m█████▍    \u001b[0m| 563/1034 [21:10<29:30,  3.76s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (961 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  55%|\u001b[31m█████▍    \u001b[0m| 564/1034 [21:13<28:21,  3.62s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  55%|\u001b[31m█████▍    \u001b[0m| 565/1034 [21:17<27:43,  3.55s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  55%|\u001b[31m█████▍    \u001b[0m| 566/1034 [21:20<26:55,  3.45s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  55%|\u001b[31m█████▍    \u001b[0m| 567/1034 [21:25<30:10,  3.88s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  55%|\u001b[31m█████▍    \u001b[0m| 568/1034 [21:27<25:32,  3.29s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  55%|\u001b[31m█████▌    \u001b[0m| 569/1034 [21:29<23:00,  2.97s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  55%|\u001b[31m█████▌    \u001b[0m| 570/1034 [21:32<23:32,  3.04s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  55%|\u001b[31m█████▌    \u001b[0m| 571/1034 [21:36<24:29,  3.17s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  55%|\u001b[31m█████▌    \u001b[0m| 572/1034 [21:39<24:52,  3.23s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (980 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  55%|\u001b[31m█████▌    \u001b[0m| 573/1034 [21:42<24:53,  3.24s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  56%|\u001b[31m█████▌    \u001b[0m| 574/1034 [21:46<25:09,  3.28s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (969 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  56%|\u001b[31m█████▌    \u001b[0m| 575/1034 [21:49<26:03,  3.41s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (966 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  56%|\u001b[31m█████▌    \u001b[0m| 576/1034 [21:53<26:40,  3.49s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  56%|\u001b[31m█████▌    \u001b[0m| 577/1034 [21:57<27:37,  3.63s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (961 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  56%|\u001b[31m█████▌    \u001b[0m| 578/1034 [21:59<23:51,  3.14s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  56%|\u001b[31m█████▌    \u001b[0m| 579/1034 [22:02<24:30,  3.23s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  56%|\u001b[31m█████▌    \u001b[0m| 580/1034 [22:07<27:23,  3.62s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (966 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  56%|\u001b[31m█████▌    \u001b[0m| 581/1034 [22:10<26:34,  3.52s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  56%|\u001b[31m█████▋    \u001b[0m| 582/1034 [22:13<25:43,  3.42s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  56%|\u001b[31m█████▋    \u001b[0m| 583/1034 [22:16<24:46,  3.30s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  56%|\u001b[31m█████▋    \u001b[0m| 584/1034 [22:20<24:14,  3.23s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  89%|\u001b[31m████████▉ \u001b[0m| 918/1034 [33:53<04:59,  2.58s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  89%|\u001b[31m████████▉ \u001b[0m| 919/1034 [33:55<04:32,  2.37s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  89%|\u001b[31m████████▉ \u001b[0m| 920/1034 [33:58<04:34,  2.41s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  89%|\u001b[31m████████▉ \u001b[0m| 921/1034 [34:00<04:32,  2.41s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  89%|\u001b[31m████████▉ \u001b[0m| 922/1034 [34:02<04:16,  2.29s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  89%|\u001b[31m████████▉ \u001b[0m| 923/1034 [34:05<04:34,  2.48s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  89%|\u001b[31m████████▉ \u001b[0m| 924/1034 [34:08<04:48,  2.63s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  89%|\u001b[31m████████▉ \u001b[0m| 925/1034 [34:11<05:07,  2.82s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  90%|\u001b[31m████████▉ \u001b[0m| 926/1034 [34:14<04:51,  2.70s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  90%|\u001b[31m████████▉ \u001b[0m| 927/1034 [34:16<04:27,  2.50s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  90%|\u001b[31m████████▉ \u001b[0m| 928/1034 [34:20<05:29,  3.10s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  90%|\u001b[31m████████▉ \u001b[0m| 929/1034 [34:22<04:52,  2.79s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  90%|\u001b[31m████████▉ \u001b[0m| 930/1034 [34:26<05:10,  2.98s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  90%|\u001b[31m█████████ \u001b[0m| 931/1034 [34:28<04:54,  2.86s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  90%|\u001b[31m█████████ \u001b[0m| 932/1034 [34:30<04:28,  2.64s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  90%|\u001b[31m█████████ \u001b[0m| 933/1034 [34:32<04:00,  2.38s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  90%|\u001b[31m█████████ \u001b[0m| 934/1034 [34:35<04:17,  2.57s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  90%|\u001b[31m█████████ \u001b[0m| 935/1034 [34:37<03:50,  2.33s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  91%|\u001b[31m█████████ \u001b[0m| 936/1034 [34:39<03:39,  2.24s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  91%|\u001b[31m█████████ \u001b[0m| 937/1034 [34:42<03:56,  2.43s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  91%|\u001b[31m█████████ \u001b[0m| 938/1034 [34:45<04:12,  2.63s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  91%|\u001b[31m█████████ \u001b[0m| 939/1034 [34:48<04:24,  2.78s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  91%|\u001b[31m█████████ \u001b[0m| 940/1034 [34:51<04:21,  2.78s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  91%|\u001b[31m█████████ \u001b[0m| 941/1034 [34:53<04:03,  2.62s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  91%|\u001b[31m█████████ \u001b[0m| 942/1034 [34:56<04:07,  2.69s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  91%|\u001b[31m█████████ \u001b[0m| 943/1034 [34:58<03:38,  2.41s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  91%|\u001b[31m█████████▏\u001b[0m| 944/1034 [35:00<03:48,  2.54s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  91%|\u001b[31m█████████▏\u001b[0m| 945/1034 [35:02<03:29,  2.35s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  91%|\u001b[31m█████████▏\u001b[0m| 946/1034 [35:06<03:48,  2.59s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  92%|\u001b[31m█████████▏\u001b[0m| 947/1034 [35:08<03:46,  2.61s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  92%|\u001b[31m█████████▏\u001b[0m| 948/1034 [35:11<03:40,  2.57s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  92%|\u001b[31m█████████▏\u001b[0m| 949/1034 [35:13<03:20,  2.35s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  92%|\u001b[31m█████████▏\u001b[0m| 950/1034 [35:14<02:56,  2.11s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  92%|\u001b[31m█████████▏\u001b[0m| 951/1034 [35:16<02:47,  2.02s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  92%|\u001b[31m█████████▏\u001b[0m| 952/1034 [35:18<02:40,  1.95s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  92%|\u001b[31m█████████▏\u001b[0m| 953/1034 [35:19<02:30,  1.86s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  92%|\u001b[31m█████████▏\u001b[0m| 954/1034 [35:21<02:23,  1.79s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  92%|\u001b[31m█████████▏\u001b[0m| 955/1034 [35:24<02:47,  2.11s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  92%|\u001b[31m█████████▏\u001b[0m| 956/1034 [35:27<03:21,  2.58s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  93%|\u001b[31m█████████▎\u001b[0m| 957/1034 [35:29<03:05,  2.41s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  93%|\u001b[31m█████████▎\u001b[0m| 958/1034 [35:32<02:55,  2.31s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  93%|\u001b[31m█████████▎\u001b[0m| 959/1034 [35:33<02:39,  2.13s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  93%|\u001b[31m█████████▎\u001b[0m| 960/1034 [35:35<02:35,  2.10s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  93%|\u001b[31m█████████▎\u001b[0m| 961/1034 [35:39<02:57,  2.44s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  93%|\u001b[31m█████████▎\u001b[0m| 962/1034 [35:42<03:18,  2.75s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  93%|\u001b[31m█████████▎\u001b[0m| 963/1034 [35:44<03:02,  2.57s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  93%|\u001b[31m█████████▎\u001b[0m| 964/1034 [35:46<02:50,  2.43s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  93%|\u001b[31m█████████▎\u001b[0m| 965/1034 [35:48<02:32,  2.21s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  93%|\u001b[31m█████████▎\u001b[0m| 966/1034 [35:51<02:42,  2.39s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  94%|\u001b[31m█████████▎\u001b[0m| 967/1034 [35:53<02:32,  2.28s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  94%|\u001b[31m█████████▎\u001b[0m| 968/1034 [35:55<02:29,  2.27s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  94%|\u001b[31m█████████▎\u001b[0m| 969/1034 [35:57<02:16,  2.10s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  94%|\u001b[31m█████████▍\u001b[0m| 970/1034 [35:59<02:08,  2.00s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  94%|\u001b[31m█████████▍\u001b[0m| 971/1034 [36:01<02:19,  2.22s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  94%|\u001b[31m█████████▍\u001b[0m| 972/1034 [36:03<02:11,  2.13s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  94%|\u001b[31m█████████▍\u001b[0m| 973/1034 [36:05<02:05,  2.05s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  94%|\u001b[31m█████████▍\u001b[0m| 974/1034 [36:07<02:09,  2.15s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  94%|\u001b[31m█████████▍\u001b[0m| 975/1034 [36:10<02:18,  2.34s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  94%|\u001b[31m█████████▍\u001b[0m| 976/1034 [36:12<02:10,  2.24s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  94%|\u001b[31m█████████▍\u001b[0m| 977/1034 [36:15<02:15,  2.38s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  95%|\u001b[31m█████████▍\u001b[0m| 978/1034 [36:16<01:58,  2.12s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  95%|\u001b[31m█████████▍\u001b[0m| 979/1034 [36:18<01:47,  1.95s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  95%|\u001b[31m█████████▍\u001b[0m| 980/1034 [36:23<02:41,  2.99s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  95%|\u001b[31m█████████▍\u001b[0m| 981/1034 [36:26<02:27,  2.78s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  95%|\u001b[31m█████████▍\u001b[0m| 982/1034 [36:28<02:12,  2.55s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  95%|\u001b[31m█████████▌\u001b[0m| 983/1034 [36:29<01:54,  2.24s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  95%|\u001b[31m█████████▌\u001b[0m| 984/1034 [36:31<01:49,  2.18s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  95%|\u001b[31m█████████▌\u001b[0m| 985/1034 [36:33<01:43,  2.11s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  95%|\u001b[31m█████████▌\u001b[0m| 986/1034 [36:35<01:42,  2.13s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  95%|\u001b[31m█████████▌\u001b[0m| 987/1034 [36:38<01:42,  2.18s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  96%|\u001b[31m█████████▌\u001b[0m| 988/1034 [36:40<01:36,  2.09s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  96%|\u001b[31m█████████▌\u001b[0m| 989/1034 [36:41<01:28,  1.97s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  96%|\u001b[31m█████████▌\u001b[0m| 990/1034 [36:43<01:26,  1.96s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  96%|\u001b[31m█████████▌\u001b[0m| 991/1034 [36:45<01:19,  1.86s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  96%|\u001b[31m█████████▌\u001b[0m| 992/1034 [36:46<01:14,  1.77s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  96%|\u001b[31m█████████▌\u001b[0m| 993/1034 [36:49<01:29,  2.17s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  96%|\u001b[31m█████████▌\u001b[0m| 994/1034 [36:52<01:27,  2.19s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  96%|\u001b[31m█████████▌\u001b[0m| 995/1034 [36:54<01:25,  2.19s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  96%|\u001b[31m█████████▋\u001b[0m| 996/1034 [36:56<01:19,  2.10s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  96%|\u001b[31m█████████▋\u001b[0m| 997/1034 [36:58<01:13,  1.99s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  97%|\u001b[31m█████████▋\u001b[0m| 998/1034 [37:00<01:20,  2.25s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...:  97%|\u001b[31m█████████▋\u001b[0m| 999/1034 [37:02<01:14,  2.13s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...: 100%|\u001b[31m█████████▉\u001b[0m| 1030/1034 [38:00<00:06,  1.65s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...: 100%|\u001b[31m█████████▉\u001b[0m| 1031/1034 [38:03<00:05,  1.94s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...: 100%|\u001b[31m█████████▉\u001b[0m| 1032/1034 [38:05<00:04,  2.02s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...: 100%|\u001b[31m█████████▉\u001b[0m| 1033/1034 [38:07<00:02,  2.00s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Gerando Predições...: 100%|\u001b[31m██████████\u001b[0m| 1034/1034 [38:10<00:00,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "model_path = os.path.join(OUTPUT_MODEL, \"\")\n",
        "predictions = []\n",
        "\n",
        "progress_bar = tqdm(total=len(dataset[\"test\"]), desc=\"Gerando Predições...\", colour=\"red\")\n",
        "for data in dataset[\"test\"]:\n",
        "    # print(f\"Complexidade: {data['difficulty']}\")\n",
        "    # print(f\"Query: {data['instruction'] + data['input']}\")\n",
        "    # print(f\"Resposta esperada: {data['output']}\")\n",
        "    # print(f\"Resposta gerada: {use_ajusted_model(model_path, data['instruction'] + data['input'])}\")\n",
        "    # print(\"\\n################################\\n\")\n",
        "\n",
        "    predictions.append(\n",
        "        Prediction(\n",
        "            db_id=data['db_id'],\n",
        "            difficulty=data['difficulty'],\n",
        "            instruction=data['instruction'],\n",
        "            nl=data['input'],\n",
        "            sql_expected=data['output'],\n",
        "            sql_predicted=use_ajusted_model(model_path, data['instruction'] + data['input'])\n",
        "        ).model_dump()\n",
        "    )\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "# Escrever o JSON em um arquivo\n",
        "with open(os.path.join(OUTPUT_MODEL, 'predictions.json'), 'w') as f:\n",
        "    f.write(json.dumps(predictions, indent=4))\n",
        "\n",
        "print(\"Predictions saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI_Ovvg0Gqg8"
      },
      "source": [
        "### Exemplo uso T5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y6bWwrCmBXL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import os\n",
        "import nltk\n",
        "import time\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, EarlyStoppingCallback\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "def preprocess_function(examples, max_input_len_, max_target_len_, tokenizer_):\n",
        "    model_inputs = tokenizer_(examples['text'], max_length=max_input_len_, truncation=True)\n",
        "    labels = tokenizer_(examples['summary'], max_length=max_target_len_, truncation=True)\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "def compute_eval_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    decoded_preds = ['\\n'.join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = ['\\n'.join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    result = rouge.compute(predictions=decoded_preds,\n",
        "                           references=decoded_labels,\n",
        "                           use_stemmer=False)\n",
        "    result = {key: value for key, value in result.items()}\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result['gen_len'] = np.mean(prediction_lens)\n",
        "    return {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    is_turn_off_computer = False\n",
        "\n",
        "    # model_name = 'ptt5_small'\n",
        "    # model_name = 'ptt5_base'\n",
        "    # model_name = 'ptt5_large'\n",
        "\n",
        "    # model_name = 'flan_t5_small'\n",
        "    # model_name = 'flan_t5_base'\n",
        "    model_name = 'flan_t5_large'\n",
        "\n",
        "    # model_name = 'ptt5_v2_small'\n",
        "    # model_name = 'ptt5_v2_base'\n",
        "    # model_name = 'ptt5_v2_large'\n",
        "\n",
        "    dataset_name = 'recognasumm'\n",
        "    # dataset_name = 'xlsum'\n",
        "\n",
        "    use_fp16 = False\n",
        "\n",
        "    models_dir = '../../data/models'\n",
        "    training_dir = '../../data/training'\n",
        "\n",
        "    n_examples = -1\n",
        "\n",
        "    num_epochs = 20\n",
        "\n",
        "    max_input_len = 512\n",
        "    max_summary_len = 150\n",
        "\n",
        "    batch_size = 32\n",
        "\n",
        "    if model_name == 'flan_t5_base' or model_name == 'ptt5_v2_base':\n",
        "        batch_size = 8\n",
        "    elif model_name == 'flan_t5_large':\n",
        "        batch_size = 3\n",
        "    elif '_large' in model_name:\n",
        "        batch_size = 4\n",
        "\n",
        "    model_checkpoint = None\n",
        "\n",
        "    if model_name == 'flan_t5_small':\n",
        "        model_checkpoint = 'google/flan-t5-small'\n",
        "    elif model_name == 'flan_t5_base':\n",
        "        model_checkpoint = 'google/flan-t5-base'\n",
        "    elif model_name == 'flan_t5_large':\n",
        "        model_checkpoint = 'google/flan-t5-large'\n",
        "    elif model_name == 'ptt5_small':\n",
        "        model_checkpoint = 'unicamp-dl/ptt5-small-portuguese-vocab'\n",
        "    elif model_name == 'ptt5_base':\n",
        "        model_checkpoint = 'unicamp-dl/ptt5-base-portuguese-vocab'\n",
        "    elif model_name == 'ptt5_large':\n",
        "        model_checkpoint = 'unicamp-dl/ptt5-large-portuguese-vocab'\n",
        "    elif model_name == 'ptt5_v2_small':\n",
        "        model_checkpoint = 'unicamp-dl/ptt5-v2-small'\n",
        "    elif model_name == 'ptt5_v2_base':\n",
        "        model_checkpoint = 'unicamp-dl/ptt5-v2-base'\n",
        "    elif model_name == 'ptt5_v2_large':\n",
        "        model_checkpoint = 'unicamp-dl/ptt5-v2-large'\n",
        "    else:\n",
        "        print(f'\\nError. Model Name {model_name} not found!')\n",
        "        exit(-1)\n",
        "\n",
        "    model_path = os.path.join(models_dir, f'{model_name}_{dataset_name}')\n",
        "\n",
        "    output_dir = f'{training_dir}/{model_name}_{dataset_name}'\n",
        "\n",
        "    os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    print(f'\\nDevice: {device} -- Use FP16: {use_fp16} -- Batch size: {batch_size} -- '\n",
        "          f'Turn Off Computer: {is_turn_off_computer}')\n",
        "\n",
        "    print(f'\\nModel: {model_name} -- {model_checkpoint}')\n",
        "\n",
        "    if dataset_name == 'xlsum':\n",
        "        dataset = load_dataset('csebuetnlp/xlsum', 'portuguese')\n",
        "    elif dataset_name == 'recognasumm':\n",
        "        dataset = load_dataset(\"recogna-nlp/recognasumm\")\n",
        "        dataset = dataset.rename_column(\"index\", \"id\")\n",
        "        dataset = dataset.rename_column(\"Noticia\", \"text\")\n",
        "        dataset = dataset.rename_column(\"Sumario\", \"summary\")\n",
        "    else:\n",
        "        print(f'\\nError. DATASET Name {dataset_name} Invalid!')\n",
        "        exit(-1)\n",
        "\n",
        "    # dataset = dataset.filter(lambda example: len(example['summary'].split()) >= 25)\n",
        "\n",
        "    if n_examples > 0:\n",
        "        train_dataset = dataset['train'].select(range(n_examples))\n",
        "        validation_dataset = dataset['validation'].select(range(n_examples))\n",
        "    else:\n",
        "        train_dataset = dataset['train']\n",
        "        validation_dataset = dataset['validation']\n",
        "\n",
        "    print(f'\\nTrain: {len(train_dataset)}')\n",
        "    print(f'Validation: {len(validation_dataset)}\\n')\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, legacy=False)\n",
        "\n",
        "    train_encoded_dataset = train_dataset.map(\n",
        "        preprocess_function, batched=True, fn_kwargs={\n",
        "            'max_input_len_': max_input_len, 'max_target_len_': max_summary_len,\n",
        "            'tokenizer_': tokenizer})\n",
        "\n",
        "    validation_encoded_dataset = validation_dataset.map(\n",
        "        preprocess_function, batched=True, fn_kwargs={\n",
        "            'max_input_len_': max_input_len, 'max_target_len_': max_summary_len,\n",
        "            'tokenizer_': tokenizer})\n",
        "\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "    logging_eval_steps = len(train_encoded_dataset) // batch_size\n",
        "\n",
        "    train_args = Seq2SeqTrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=num_epochs,\n",
        "        learning_rate=5.6e-5,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        weight_decay=0.01,\n",
        "        eval_steps=logging_eval_steps,\n",
        "        logging_steps=logging_eval_steps,\n",
        "        evaluation_strategy='epoch',\n",
        "        predict_with_generate=True,\n",
        "        save_total_limit=1,\n",
        "        save_strategy='epoch',\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='rougeL',\n",
        "        greater_is_better=True,\n",
        "        push_to_hub=False,\n",
        "        fp16=use_fp16\n",
        "    )\n",
        "\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=model,\n",
        "        args=train_args,\n",
        "        train_dataset=train_encoded_dataset,\n",
        "        eval_dataset=validation_encoded_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_eval_metrics,\n",
        "        callbacks=[\n",
        "            EarlyStoppingCallback(\n",
        "                early_stopping_patience=5\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    if os.path.exists(output_dir) and len(os.listdir(output_dir)) > 0:\n",
        "        trainer.train(resume_from_checkpoint=True)\n",
        "    else:\n",
        "        trainer.train()\n",
        "\n",
        "    trainer.evaluate()\n",
        "\n",
        "    trainer.save_model(model_path)\n",
        "\n",
        "    print('\\n\\n***Finetunning Complete!***')\n",
        "\n",
        "    if is_turn_off_computer:\n",
        "        print('\\nTurning off computer ...')\n",
        "        time.sleep(2 * 60)\n",
        "        os.system('shutdown -h now')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arhLgu0tAuEK"
      },
      "source": [
        "## categorização do dataset spider de acordo com a complexidade(dificuldade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2oidcSOA2gb"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_sql_difficulty(sql_query):\n",
        "    \"\"\"Classifica o nível de dificuldade do SQL com base nos critérios do Spider.\"\"\"\n",
        "    # Contar o número de colunas no SELECT\n",
        "    select_match = re.search(r\"\\bSELECT\\b\\s+(.*?)(\\bFROM\\b)\", sql_query, re.IGNORECASE | re.DOTALL)\n",
        "    if select_match:\n",
        "        select_columns = select_match.group(1).split(\",\")\n",
        "        num_select = len([col.strip() for col in select_columns if col.strip()])\n",
        "    else:\n",
        "        num_select = 0\n",
        "\n",
        "    # Contar o número de condições no WHERE\n",
        "    where_conditions = re.findall(r\"\\bWHERE\\b(.*?)(\\bGROUP BY\\b|\\bORDER BY\\b|$)\", sql_query, re.IGNORECASE | re.DOTALL)\n",
        "    num_where = 0\n",
        "    if where_conditions:\n",
        "        where_clause = where_conditions[0][0]\n",
        "        num_where = len(re.findall(r\"AND|OR\", where_clause, re.IGNORECASE)) if where_clause.strip() else 0\n",
        "\n",
        "    # Contar o número de colunas no GROUP BY\n",
        "    group_by_match = re.search(r\"\\bGROUP BY\\b\\s+(.*?)(\\bORDER BY\\b|$)\", sql_query, re.IGNORECASE | re.DOTALL)\n",
        "    if group_by_match:\n",
        "        group_by_columns = group_by_match.group(1).split(\",\")\n",
        "        num_group_by = len([col.strip() for col in group_by_columns if col.strip()])\n",
        "    else:\n",
        "        num_group_by = 0\n",
        "\n",
        "    # Contar o número de colunas no ORDER BY\n",
        "    order_by_match = re.search(r\"\\bORDER BY\\b\\s+(.*?)(LIMIT|$)\", sql_query, re.IGNORECASE | re.DOTALL)\n",
        "    if order_by_match:\n",
        "        order_by_columns = order_by_match.group(1).split(\",\")\n",
        "        num_order_by = len([col.strip() for col in order_by_columns if col.strip()])\n",
        "    else:\n",
        "        num_order_by = 0\n",
        "\n",
        "    # Contar subconsultas com base nos parênteses\n",
        "    num_nested = len(re.findall(r\"\\(SELECT\\b\", sql_query, re.IGNORECASE))\n",
        "\n",
        "    # Contar o número de junções (JOIN)\n",
        "    num_joins = len(re.findall(r\"\\bJOIN\\b\", sql_query, re.IGNORECASE))\n",
        "\n",
        "    # Verificar a presença de EXCEPT, INTERSECT e UNION\n",
        "    has_except = bool(re.search(r\"\\bEXCEPT\\b\", sql_query, re.IGNORECASE))\n",
        "    has_intersect = bool(re.search(r\"\\bINTERSECT\\b\", sql_query, re.IGNORECASE))\n",
        "    has_union = bool(re.search(r\"\\bUNION\\b\", sql_query, re.IGNORECASE))\n",
        "\n",
        "    # Critério especial para subconsultas com JOIN\n",
        "    has_nested_join = bool(\n",
        "        re.search(r\"\\(SELECT\\b.*?\\bJOIN\\b\", sql_query, re.IGNORECASE | re.DOTALL)\n",
        "    )\n",
        "\n",
        "    # Classificação de dificuldade com base nos critérios do Spider\n",
        "    if has_union:\n",
        "        return \"extra hard\"  # `UNION` é sempre \"extra hard\"\n",
        "    elif has_nested_join or num_nested > 1:\n",
        "        return \"extra hard\"  # Subconsulta com JOIN ou múltiplas subconsultas\n",
        "    elif (\n",
        "        num_select <= 1\n",
        "        and num_where <= 1\n",
        "        and num_group_by == 0\n",
        "        and num_order_by == 0\n",
        "        and num_nested == 0\n",
        "        and num_joins == 0\n",
        "        and not (has_except or has_intersect)\n",
        "    ):\n",
        "        print(f\"Num Select: {num_select}\\nNum Joins: {num_joins}\\nNum Where: {num_where}\\nNum Group By: {num_group_by}\\nNum Order By: {num_order_by}\\nNum Nested: {num_nested}\")\n",
        "        return \"easy\"\n",
        "    elif (\n",
        "        num_select <= 3\n",
        "        and num_where <= 2\n",
        "        and num_group_by <= 1\n",
        "        and num_order_by <= 1\n",
        "        and num_nested == 0\n",
        "        and num_joins <= 1\n",
        "        and not (has_except or has_intersect)\n",
        "    ):\n",
        "        print(f\"Num Select: {num_select}\\nNum Joins: {num_joins}\\nNum Where: {num_where}\\nNum Group By: {num_group_by}\\nNum Order By: {num_order_by}\\nNum Nested: {num_nested}\")\n",
        "        return \"medium\"\n",
        "    elif (\n",
        "        num_group_by > 1\n",
        "        or num_order_by > 1\n",
        "        or num_nested > 0\n",
        "        or num_where > 2\n",
        "        or num_joins > 1\n",
        "        or has_except\n",
        "        or has_intersect\n",
        "    ):\n",
        "        print(f\"Num Select: {num_select}\\nNum Joins: {num_joins}\\nNum Where: {num_where}\\nNum Group By: {num_group_by}\\nNum Order By: {num_order_by}\\nNum Nested: {num_nested}\")\n",
        "        return \"hard\"\n",
        "    else:\n",
        "        return \"extra hard\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLFmAf65K4yz"
      },
      "outputs": [],
      "source": [
        "get_sql_difficulty(\"SELECT name, price FROM products WHERE catergory = 'Eletronics' AND voltage = 110\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfyeiHgfCU0t"
      },
      "outputs": [],
      "source": [
        "get_sql_difficulty(\"SELECT AVG(price) FROM products WHERE category = 'Electronics'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMaKwAJaCnO3"
      },
      "outputs": [],
      "source": [
        "get_sql_difficulty(\"SELECT category, COUNT(*) FROM products GROUP BY category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooOxtW4bCyo4"
      },
      "outputs": [],
      "source": [
        "get_sql_difficulty(\"SELECT product_name, price FROM products\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7DBFtuVMhOP"
      },
      "outputs": [],
      "source": [
        "# prompt: gere um exemplo de uma consulta sql que realize uma junção a esquerda colocando alias em cada tabela\n",
        "get_sql_difficulty(\"SELECT c.customer_name, o.order_id FROM customers c LEFT JOIN orders o ON c.customer_id = o.customer_id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1Sn1ze7NBQL"
      },
      "outputs": [],
      "source": [
        "# prompt: gere um exemplo de uma consulta sql que realize uma junção a esquerda e uma junção a direita com uma subconsulta colocando alias em cada tabela\n",
        "sql1 = (\"SELECT \"\n",
        "    + \"c.customer_id, \"\n",
        "    + \"c.customer_name, \"\n",
        "    + \"o.order_id \"\n",
        "+ \"FROM \"\n",
        "    + \"customers c \"\n",
        "+ \"LEFT JOIN \"\n",
        "    + \"(SELECT order_id, customer_id FROM orders WHERE order_date > '2023-01-01') o \"\n",
        "+ \"ON \"\n",
        "    + \"c.customer_id = o.customer_id; \")\n",
        "\n",
        "\n",
        "\n",
        "sql2 = (\"SELECT\"\n",
        "    + \"o.order_id, \"\n",
        "    + \"o.order_date, \"\n",
        "    + \"c.customer_name \"\n",
        "+ \"FROM \"\n",
        "    + \"(SELECT order_id, order_date, customer_id FROM orders WHERE order_status = 'Shipped') o \"\n",
        "+ \"RIGHT JOIN \"\n",
        "    + \"customers c \"\n",
        "+ \"ON \"\n",
        "    + \"o.customer_id = c.customer_id; \")\n",
        "\n",
        "print(get_sql_difficulty(sql1))\n",
        "print(\"\\n\")\n",
        "print(get_sql_difficulty(sql2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5QDt85nPSMB"
      },
      "outputs": [],
      "source": [
        "# prompt: gere uma consulta sql para retornar todos os alunos que estão matriculado em matemática\n",
        "print(get_sql_difficulty(\"SELECT s.student_name FROM Students s JOIN Enrollments e ON s.student_id = e.student_id JOIN Courses c ON e.course_id = c.course_id WHERE c.course_name = 'Matemática'\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaYR_aJMnxXc"
      },
      "outputs": [],
      "source": [
        "get_sql_difficulty(\"SELECT name ,  born_state ,  age FROM head ORDER BY age\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOKWK9utn4AV"
      },
      "outputs": [],
      "source": [
        "get_sql_difficulty(\"SELECT T1.country_name FROM countries AS T1 JOIN continents AS T2 ON T1.continent = T2.cont_id JOIN car_makers AS T3 ON T1.country_id = T3.country WHERE T2.continent = 'Europe' GROUP BY T1.country_name HAVING COUNT(*) >= 3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqZNqo9eoQjY"
      },
      "outputs": [],
      "source": [
        "get_sql_difficulty(\"SELECT T2.name, COUNT(*) FROM concert AS T1 JOIN stadium AS T2 ON T1.stadium_id = T2.stadium_id GROUP BY T1.stadium_id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1LpTE0NoXj-"
      },
      "outputs": [],
      "source": [
        "get_sql_difficulty(\"SELECT COUNT(*) FROM cars_data WHERE cylinders > 4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rodIRh_comyw"
      },
      "outputs": [],
      "source": [
        "get_sql_difficulty(\"SELECT AVG(life_expectancy) FROM country WHERE name NOT IN (SELECT T1.name FROM country AS T1 JOIN country_language AS T2 ON T1.code = T2.country_code WHERE T2.language = 'English' AND T2.is_official = 'T')\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nI_Ovvg0Gqg8",
        "arhLgu0tAuEK"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e78157dd4935451e8b113d24fa449255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_179582a7b5ba4c619fa7b1350c393296",
              "IPY_MODEL_d97459b59bda47d290b7b7ee01b895ca",
              "IPY_MODEL_8f08f2b48eff45878ff680f82d7740bb"
            ],
            "layout": "IPY_MODEL_7fcc46c39bf64fe3a1bfe7e0131273f7"
          }
        },
        "179582a7b5ba4c619fa7b1350c393296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c82fefca51416e825d139ea48809ca",
            "placeholder": "​",
            "style": "IPY_MODEL_cbac24a409604584a2500df16664a957",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d97459b59bda47d290b7b7ee01b895ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d90c469f65b4cd5970badce15216ba7",
            "max": 2539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40c68c11fa594227bcd0171ea6051ca0",
            "value": 2539
          }
        },
        "8f08f2b48eff45878ff680f82d7740bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ad73f37af6744fea95b99c11d5f92b4",
            "placeholder": "​",
            "style": "IPY_MODEL_a5feb3710c9a49b6ac70c8c12ca42704",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 109kB/s]"
          }
        },
        "7fcc46c39bf64fe3a1bfe7e0131273f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96c82fefca51416e825d139ea48809ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbac24a409604584a2500df16664a957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d90c469f65b4cd5970badce15216ba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40c68c11fa594227bcd0171ea6051ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ad73f37af6744fea95b99c11d5f92b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5feb3710c9a49b6ac70c8c12ca42704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bc06334bd7d44f4bc1bf097cfa4da71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ece541d7edbe4ddfa9387c165d571781",
              "IPY_MODEL_b4b5d86296824719a556e52a127d83d6",
              "IPY_MODEL_1f59c942836f46cf98439de681fe0549"
            ],
            "layout": "IPY_MODEL_bf3cf2dcf25c467d8f4ce909c0c4a466"
          }
        },
        "ece541d7edbe4ddfa9387c165d571781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16839ac362a4129925da060d9e72143",
            "placeholder": "​",
            "style": "IPY_MODEL_a598538d2912418e8309a71af18b98e1",
            "value": "spiece.model: 100%"
          }
        },
        "b4b5d86296824719a556e52a127d83d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d5a66233fe341789d6be504d48ab8ec",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_343130836cb6408a8cfbc627537651bd",
            "value": 791656
          }
        },
        "1f59c942836f46cf98439de681fe0549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebc108c1755748de94847e0fbbdd25c5",
            "placeholder": "​",
            "style": "IPY_MODEL_6b6ab5c47eec45ed9b0966f9f2bfd2fd",
            "value": " 792k/792k [00:00&lt;00:00, 12.4MB/s]"
          }
        },
        "bf3cf2dcf25c467d8f4ce909c0c4a466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c16839ac362a4129925da060d9e72143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a598538d2912418e8309a71af18b98e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d5a66233fe341789d6be504d48ab8ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "343130836cb6408a8cfbc627537651bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebc108c1755748de94847e0fbbdd25c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b6ab5c47eec45ed9b0966f9f2bfd2fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b671ed72e2954a5ba371057a4404fb98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_beb8c1bb542145a9ae3e3658bbcf08ce",
              "IPY_MODEL_dc7c5032bb3040768ba06bf762be59db",
              "IPY_MODEL_8f6e9165cedf4be4a459c11686b8bab5"
            ],
            "layout": "IPY_MODEL_2be14612767343ee88e8cccba644b127"
          }
        },
        "beb8c1bb542145a9ae3e3658bbcf08ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b48285e1d1549e7aacd5346bceeb99e",
            "placeholder": "​",
            "style": "IPY_MODEL_9a5c982507ee4afe9503ba170be47869",
            "value": "tokenizer.json: 100%"
          }
        },
        "dc7c5032bb3040768ba06bf762be59db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc6927321a144298a96957a8ec992159",
            "max": 2424064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e0fa77255de4cf88472fdecbc77ef26",
            "value": 2424064
          }
        },
        "8f6e9165cedf4be4a459c11686b8bab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1009edc48d4240a2b0c3f01a3abb6eaf",
            "placeholder": "​",
            "style": "IPY_MODEL_397117f2debe450ab8878e96656c1884",
            "value": " 2.42M/2.42M [00:00&lt;00:00, 5.48MB/s]"
          }
        },
        "2be14612767343ee88e8cccba644b127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b48285e1d1549e7aacd5346bceeb99e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a5c982507ee4afe9503ba170be47869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc6927321a144298a96957a8ec992159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e0fa77255de4cf88472fdecbc77ef26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1009edc48d4240a2b0c3f01a3abb6eaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397117f2debe450ab8878e96656c1884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9213a19a6bed41f78f510d3c5c30b511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2d13e60781246c9baa70f7dd92ce313",
              "IPY_MODEL_f6d9a2f3e4e34bcbab4a794596f405a4",
              "IPY_MODEL_9459348d115247bcad2bf4f7d85c7b40"
            ],
            "layout": "IPY_MODEL_2e6470a5b2704f818dab14ca1e856d34"
          }
        },
        "e2d13e60781246c9baa70f7dd92ce313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5732b90931484cdab9354064a6e7ee60",
            "placeholder": "​",
            "style": "IPY_MODEL_d7b5c047fb7f4415bcc5af2816e1405f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f6d9a2f3e4e34bcbab4a794596f405a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05199515c5104231a2b3dbf9c606b259",
            "max": 2201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33114afa3b9b4d188466e24fbb0803df",
            "value": 2201
          }
        },
        "9459348d115247bcad2bf4f7d85c7b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fec53d78d51848d2879625a4424d97e6",
            "placeholder": "​",
            "style": "IPY_MODEL_40813ed5846549899d7b8960cecb6a52",
            "value": " 2.20k/2.20k [00:00&lt;00:00, 44.7kB/s]"
          }
        },
        "2e6470a5b2704f818dab14ca1e856d34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5732b90931484cdab9354064a6e7ee60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b5c047fb7f4415bcc5af2816e1405f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05199515c5104231a2b3dbf9c606b259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33114afa3b9b4d188466e24fbb0803df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fec53d78d51848d2879625a4424d97e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40813ed5846549899d7b8960cecb6a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02e19e32c2d0441daef15d4dc62bea90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88a8723c067c414da2a423c4042202fe",
              "IPY_MODEL_ece980062e1a4da1ab037115f12c84ad",
              "IPY_MODEL_e03e061799b84a7c87ffb4c47dae6257"
            ],
            "layout": "IPY_MODEL_adecc803eb4a462d99e9084d6b510303"
          }
        },
        "88a8723c067c414da2a423c4042202fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_405c8ace55714602af43d14aaefa1fbe",
            "placeholder": "​",
            "style": "IPY_MODEL_dce20679fe2c40ad925da68b92f9d8bd",
            "value": "config.json: 100%"
          }
        },
        "ece980062e1a4da1ab037115f12c84ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2f2ecf4475f452185c9416d12eaf843",
            "max": 1401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_290c46e8cdfc4d2692ff97d865992a27",
            "value": 1401
          }
        },
        "e03e061799b84a7c87ffb4c47dae6257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11cd61678c464147b70121c85f6ae078",
            "placeholder": "​",
            "style": "IPY_MODEL_91d0dc50055f4eefb818ab5b521eb625",
            "value": " 1.40k/1.40k [00:00&lt;00:00, 32.0kB/s]"
          }
        },
        "adecc803eb4a462d99e9084d6b510303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "405c8ace55714602af43d14aaefa1fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce20679fe2c40ad925da68b92f9d8bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2f2ecf4475f452185c9416d12eaf843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "290c46e8cdfc4d2692ff97d865992a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11cd61678c464147b70121c85f6ae078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d0dc50055f4eefb818ab5b521eb625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a6797ad7e68454d997dc01ffe337b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b81e4afc639d40ef88a26d7d689b749c",
              "IPY_MODEL_82e10eddede14a48864538b4edad83c1",
              "IPY_MODEL_ac173113177c4e0a90e51db311d694ed"
            ],
            "layout": "IPY_MODEL_b5e9b76f5f7e4ec9943b85dde4b18123"
          }
        },
        "b81e4afc639d40ef88a26d7d689b749c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4006cf7e1f5a452e9d852ff720123373",
            "placeholder": "​",
            "style": "IPY_MODEL_3d6da37c89fa46f080b2d6312a682eb0",
            "value": "model.safetensors: 100%"
          }
        },
        "82e10eddede14a48864538b4edad83c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b74a174cf7734f3d8ed31e08811cfa58",
            "max": 307867048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_576d69a8b37d46d6b879d2b7526df8cc",
            "value": 307867048
          }
        },
        "ac173113177c4e0a90e51db311d694ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85243a106e074caf93098ce450d8491b",
            "placeholder": "​",
            "style": "IPY_MODEL_b8c7de9e5336482dba63e8259c46bed7",
            "value": " 308M/308M [00:01&lt;00:00, 263MB/s]"
          }
        },
        "b5e9b76f5f7e4ec9943b85dde4b18123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4006cf7e1f5a452e9d852ff720123373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d6da37c89fa46f080b2d6312a682eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b74a174cf7734f3d8ed31e08811cfa58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "576d69a8b37d46d6b879d2b7526df8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85243a106e074caf93098ce450d8491b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8c7de9e5336482dba63e8259c46bed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acb927270ea4433bb9921b11e4fc5901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56ec1d1c7c0e4046b1904ecc04772dd3",
              "IPY_MODEL_67ff9f24d7e846339f7ba6e3b6330247",
              "IPY_MODEL_adcb3de69e2c4117bc1d2c1a22318fb8"
            ],
            "layout": "IPY_MODEL_aebc48eb91874c379b577860f76ca67d"
          }
        },
        "56ec1d1c7c0e4046b1904ecc04772dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abbd8a80b05d452db14243a6b70599a0",
            "placeholder": "​",
            "style": "IPY_MODEL_7fa84b62ad9b498788f414ec69c18193",
            "value": "generation_config.json: 100%"
          }
        },
        "67ff9f24d7e846339f7ba6e3b6330247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdb3531c247a405bae8a6c3f1713782b",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_307fff7d3111442d861dd5f9f0568e94",
            "value": 147
          }
        },
        "adcb3de69e2c4117bc1d2c1a22318fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfdcb288d2da432abafba37d334aa56c",
            "placeholder": "​",
            "style": "IPY_MODEL_a751110fc4d149039d053fa407a7852b",
            "value": " 147/147 [00:00&lt;00:00, 11.7kB/s]"
          }
        },
        "aebc48eb91874c379b577860f76ca67d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbd8a80b05d452db14243a6b70599a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa84b62ad9b498788f414ec69c18193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdb3531c247a405bae8a6c3f1713782b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "307fff7d3111442d861dd5f9f0568e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfdcb288d2da432abafba37d334aa56c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a751110fc4d149039d053fa407a7852b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fb871efa5dc468aa2f67a07671f8dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d402ecd177df4299a940ef32a70b83f7",
              "IPY_MODEL_eee898ab9c6e42a4b87a3d622eddeba7",
              "IPY_MODEL_4181b213f0a44692aa7c023726d7b224"
            ],
            "layout": "IPY_MODEL_4ac12a4e0c594d448b0c3b13d1063419"
          }
        },
        "d402ecd177df4299a940ef32a70b83f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_574aa762e7ed4c5bbd3b95040ff4b2b1",
            "placeholder": "​",
            "style": "IPY_MODEL_cd4998c9a914465fb0e30515de2766a1",
            "value": "Map: 100%"
          }
        },
        "eee898ab9c6e42a4b87a3d622eddeba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1aa7ad2fd34a53b8c6110aab800f96",
            "max": 7000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd07aba79680460099ad856e2491ed13",
            "value": 7000
          }
        },
        "4181b213f0a44692aa7c023726d7b224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15974d2f574c4d9dbb77672d79805852",
            "placeholder": "​",
            "style": "IPY_MODEL_d2bb484749974e4da363ded73066b553",
            "value": " 7000/7000 [00:08&lt;00:00, 830.68 examples/s]"
          }
        },
        "4ac12a4e0c594d448b0c3b13d1063419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "574aa762e7ed4c5bbd3b95040ff4b2b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd4998c9a914465fb0e30515de2766a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f1aa7ad2fd34a53b8c6110aab800f96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd07aba79680460099ad856e2491ed13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15974d2f574c4d9dbb77672d79805852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2bb484749974e4da363ded73066b553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcf29272de2f4c84a972ca8406a4a3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e162e2ebe97f469389a74c1fb7f94440",
              "IPY_MODEL_1135beb18d22416d86e06a7f426a4aa0",
              "IPY_MODEL_c59d611dc3d94c09abce18f8b7223edd"
            ],
            "layout": "IPY_MODEL_b2fa3531d9b94280b0664e1861528f1f"
          }
        },
        "e162e2ebe97f469389a74c1fb7f94440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1661ca9f0af43db8b8392cefcec97b0",
            "placeholder": "​",
            "style": "IPY_MODEL_7685399ab03141f0ac4ae57942f22183",
            "value": "Map: 100%"
          }
        },
        "1135beb18d22416d86e06a7f426a4aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_933b1ea13b2a4c4b9e0d1a033157cc1f",
            "max": 1659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_911fabd4469e4623a8e58b4b1a149a84",
            "value": 1659
          }
        },
        "c59d611dc3d94c09abce18f8b7223edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c7d78fb63f543b982afcf5045b6cc76",
            "placeholder": "​",
            "style": "IPY_MODEL_0fb0b2a69969401b85bba3ff7de7089d",
            "value": " 1659/1659 [00:02&lt;00:00, 797.16 examples/s]"
          }
        },
        "b2fa3531d9b94280b0664e1861528f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1661ca9f0af43db8b8392cefcec97b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7685399ab03141f0ac4ae57942f22183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "933b1ea13b2a4c4b9e0d1a033157cc1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "911fabd4469e4623a8e58b4b1a149a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c7d78fb63f543b982afcf5045b6cc76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fb0b2a69969401b85bba3ff7de7089d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5124cf315bd2473bbdd618980d156b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d727fef53f646acaebc7e924e203ce1",
              "IPY_MODEL_a5250666ff834257abdde50d53ad1618",
              "IPY_MODEL_1a5b79e74dcb48d58503d3e402cd946b"
            ],
            "layout": "IPY_MODEL_ae4218a19b1841188c3e21484d3b15fe"
          }
        },
        "1d727fef53f646acaebc7e924e203ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf21ade34f67432bbe4771327d29643c",
            "placeholder": "​",
            "style": "IPY_MODEL_309d2479ebb84e8a972d606b9a845a4c",
            "value": "Map: 100%"
          }
        },
        "a5250666ff834257abdde50d53ad1618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f822fef87964b7abd29ef673d5ec567",
            "max": 1034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7409a6b0043e4c5faa60fe63ad520d17",
            "value": 1034
          }
        },
        "1a5b79e74dcb48d58503d3e402cd946b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_887b07e46de64f96b3f53ef117aca20b",
            "placeholder": "​",
            "style": "IPY_MODEL_8e672ebe4bab46aa8cced56608ca5575",
            "value": " 1034/1034 [00:00&lt;00:00, 1127.53 examples/s]"
          }
        },
        "ae4218a19b1841188c3e21484d3b15fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf21ade34f67432bbe4771327d29643c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "309d2479ebb84e8a972d606b9a845a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f822fef87964b7abd29ef673d5ec567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7409a6b0043e4c5faa60fe63ad520d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "887b07e46de64f96b3f53ef117aca20b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e672ebe4bab46aa8cced56608ca5575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b057b986432486eab0e1eeccca3820a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56a26280a4af4b599beb415441fa32e5",
              "IPY_MODEL_ea5c327fbee34231bb2ee016ba203ba5",
              "IPY_MODEL_812eaab0bc7a41c5a933dcf01f007ebf"
            ],
            "layout": "IPY_MODEL_dbfc1e2a950f4ed88c5741bff279f331"
          }
        },
        "56a26280a4af4b599beb415441fa32e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f5f7669d96e4a47b6b5f97458364229",
            "placeholder": "​",
            "style": "IPY_MODEL_adb19df799dd48f6904973b1c4dc0a3d",
            "value": "Downloading builder script: 100%"
          }
        },
        "ea5c327fbee34231bb2ee016ba203ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dc6ba9917404456987b360d995ffbb1",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7195d60d0dab423091576fbe35318e71",
            "value": 6270
          }
        },
        "812eaab0bc7a41c5a933dcf01f007ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66d3af670e5d4d61b20a149a1cc89f33",
            "placeholder": "​",
            "style": "IPY_MODEL_b1edfdc00aa442adb956fcce7dfcf5c8",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 510kB/s]"
          }
        },
        "dbfc1e2a950f4ed88c5741bff279f331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5f7669d96e4a47b6b5f97458364229": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adb19df799dd48f6904973b1c4dc0a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dc6ba9917404456987b360d995ffbb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7195d60d0dab423091576fbe35318e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66d3af670e5d4d61b20a149a1cc89f33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1edfdc00aa442adb956fcce7dfcf5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}